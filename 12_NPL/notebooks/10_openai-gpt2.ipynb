{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (1.5.0)\n",
      "Requirement already satisfied: torchvision in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from torch) (1.18.1)\n",
      "Requirement already satisfied: future in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: transformers in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (2.11.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (4.46.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: filelock in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: packaging in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: six in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: click in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/victormac/anaconda3/envs/nlp/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# install the requirements\n",
    "# !pip install torch torchvision\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modelos de Lenguaje de OpenAI\n",
    "\n",
    "A mitad de febrero, [OpenAI publicó un modelo de lenguaje](https://blog.openai.com/better-language-models/) capaz de generar lenguaje natural de formar coherente. Este modelo es generalista y, a pesar de ello, es capaz de rivalizar con los mejores sistemas específicos en tareas como comprensión automática de lenguaje natural, traducción automática, búsqueda de respuestas y resumen automático.\n",
    "\n",
    "Este modelo, llamado GPT-2, es el resultado de haber entrenado con 8 millones de páginas web (40 GB) con 1 500 millones de parámetros con un único objetivo: predecir cuál es la siguiente palabra.\n",
    "\n",
    "Sin embargo, OpenAI no ha publicado el modelo para evitar que alguien con malas intenciones pueda hacer un uso dañino de esta tecnología. Sí que han publicado una versión simplificada y más pequeña, y el paper [\"Language Models are Unsupervised Multitask Learners\"](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), en el que explican todo el proceso.\n",
    "\n",
    "Con ganas y GPUs suficientes (+ tiempo y dinero), se puede replicar el proceso. Otras lecturas interesantes, sobre el tema: \n",
    "\n",
    "- [OpenAI's new Multitalented AI Writes, Translates, and Slanders](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2)\n",
    "- [Some thoughts on zero-day threats in AI, and OpenAI's GP2](https://www.fast.ai/2019/02/15/openai-gp2/)\n",
    "\n",
    "\n",
    "Este código de ejemplo está inspirado en [un tweet de Thomas Wolf](https://twitter.com/Thom_Wolf/status/1097465312579072000), de [Hugging Face](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.47MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 958kB/s] \n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 340kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [00:45<00:00, 12.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación, definimos una función para:\n",
    "\n",
    "1. tokenizar el texto de entrada y codificarlo como un vector con los pesos obtenidos por el modelo GPT2\n",
    "2. predecir la siguiente palabra más frecuente\n",
    "3. decodificar el vector como una secuencia de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def generate(text, length=50):\n",
    "    \"\"\"Generate automatic Natural Language from the input text\"\"\"\n",
    "    vec_text = tokenizer.encode(text)\n",
    "    my_input, past = torch.tensor([vec_text]), None\n",
    "\n",
    "    for _ in range(length):\n",
    "        logits, past = model(my_input, past=past)\n",
    "        my_input = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "        vec_text.append(my_input.item())\n",
    "\n",
    "    return tokenizer.decode(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only think we can do to fight climate change is encourage policymakers to take some steps to support large-scale research into climate change.\"\n",
      "\n",
      "After the vote, an Endo Group spokesperson did not respond to requests for comment on whether the firm would hire more diverse climate scientists in the years ahead.\n",
      " \n",
      "\n",
      "The only think we can do to fight climate change is to make your administration less Incredibly authoritarian and fearful. Make sure that your administration does not impose radical Sharia law on America because all Americans believe they are right, and that doesn't include you.\n",
      "\n",
      "Let's continue to work together on tomorrow's \n",
      "\n",
      "The only think we can do to fight climate change is to start sending even more kids to South Sudan. Beyond the basic poverty problem and every other reason.\"\n",
      "\n",
      "\n",
      "Dharab Dhillon:\n",
      "\n",
      "\"Kerry is going to do his best – he's smart and a courageous man, but \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defino un texto de entrada\n",
    "text = \"The only think we can do to fight climate change is\"\n",
    "\n",
    "# y generamos automáticamente las secuencias más probables\n",
    "for _ in range(3):\n",
    "    print(generate(text, 50), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was born in Spain so I speak Spanish\n",
      "I was born in France so I speak English\n",
      "I was born in Italy so I speak no\n",
      "I was born in Greece so I speak Greek\n",
      "I was born in Russia so I speak Russian\n",
      "I was born in China so I speak no\n",
      "I was born in Japan so I speak Japanese\n",
      "I was born in India so I speak English\n"
     ]
    }
   ],
   "source": [
    "countries = \"Spain France Italy Greece Russia China Japan India\".split()\n",
    "\n",
    "for country in countries:\n",
    "    text = f\"I was born in {country} so I speak\"\n",
    "    print(generate(text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python37764bitnlpcondafc931395a4d7404f941971f950edff5c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
