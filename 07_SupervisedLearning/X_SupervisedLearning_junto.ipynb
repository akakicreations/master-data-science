{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprendizaje Supervisado con Scikit-Learn - Día 1\n",
    "\n",
    "Antes que nada, vamos a comprobar las versiones de las diferentes librerías que vamos a estar utilizando a lo largo de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "import scipy as sp\n",
    "print(\"SciPy version:\", sp.__version__)\n",
    "\n",
    "import IPython\n",
    "print(\"IPython version:\", IPython.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Por último, vamos a desactivar los mensajes de advertencia *`DeprecationWarnings`*, ya que no afectan en nada al código ni nuestros objetivos formativos para las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos un filtro de warnings\n",
    "from warnings import simplefilter\n",
    "# Ignoramos los DeprecationWarnings, en concreto el del módulo six.py\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos ciertas configuraciones iniciales\n",
    "%matplotlib inline\n",
    "from preamble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 0 - Datasets de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Una de las mejores maneras de aprender es, en general, reducir la dimensionalidad de un problema hasta comprender las cuestiones básicas y desarrollar una *intuición*.\n",
    "\n",
    "Ésta es una técnica muy utilizada en Ciencias Físicas, donde muchas veces se estudia un modelo unidimensional y luego se generaliza, con la ayuda de herramientas matemáticas, a $n$ dimensiones.\n",
    "\n",
    "Aquí haremos lo mismo gracias a una serie de Datasets básicos que utilizaremos en conjunto con otros reales a lo largo del curso."
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forge Dataset\n",
    "Utilizaremos un dataset llamado *Forge* para algunos ejemplos de modelos de clasificación supervisada. He aquí el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un dataset\n",
    "X, y = mglearn.datasets.make_forge() # Característica, Característica\n",
    "# Lo pintamos\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Clase 0\", \"Clase 1\"], loc=4)\n",
    "plt.xlabel(\"Caractística 1\")\n",
    "plt.ylabel(\"característica 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "¿Cuántos datapoints y características tiene este Dataset $X$? Utiliza Numpy para saber la respuesta, apóyate en el método `type()` de Python si necesitas saber qué métodos puedes utilizar sobre él, así como la combinación `Tab` y `Shift-Tab` para conocer la documentación de los diferentes métodos disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe la línea de código abajo\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset Wave"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utilizaremos otro dataset llamado *Wave* para los ejemplos básicos de regresión supervisada. Igualmente, utilizamos un dataset muy sencillo, de pocas dimensiones que nos ayude a visualizar y a desarrollar una intuición sobre nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un dataset\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40) #Inputs, Outputs\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Característica\")\n",
    "plt.ylabel(\"Objetivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Un ejemplo real: Wisconsin Breast Cancer Dataset\n",
    "Scikit-learn incluye algunos datasets reales con el propósito de trabajar con ellos de manera más sencilla. Éstos se almacenan como objetos `Bunch`. Lo único que es necesario saber de estos objetos por el momento es que se comportan como diccionarios de Python, con el beneficio añadido de que los valores se pueden acceder con *dot notation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys():\\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensiones del dataset:\", cancer.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cada tumor está etiquetado como *benigno* o *maligno*, y el objetivo será aprender a predecir en base a ciertas características del tejido si un tumor es benigno o maligno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conteo de muestras por clase:\\n\",\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para obtener una descripción del significado de cada una de las características, podemos usar el atributo `feature_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombres de las características:\\n\", cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Otro ejemplo real: Boston Housing Dataset\n",
    "El objetivo de este dataset es predecir el valor medio de las casas en varios barrios de Boston en la década de los '70 usando información como la tasa de criminalidad, proximidad al río Charles, acceso a autovías, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape:\", boston.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A efectos de utilizar este dataset, es mejor complementarlo considerando no sólo las 13 características iniciales, sino todos los productos entre características (llamados también *interacciones*). La generación de interacciones la haremos incrementando el grado polinómico del dataset con el transformador de Scikit Learn [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) Además, modificaremos la escala de los datos para uniformizarla y poder utilizar el concepto de medida de los datos correctamente gracias al preprocesador [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) de Scikit-Learn.\n",
    "\n",
    "El incluir características derivadas como estas se llama **Ingeniería de características**. El dataset ampliado puede cargarse gracias a la función `load_extended_boston`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función en Python para encapsular la ingeniería de características que vamos a realizar sobre el dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def load_extended_boston():\n",
    "    boston = load_boston()\n",
    "    X = boston.data\n",
    "    # Aplicamos un MinMaxScaler para escalar las características bajo un mismo criterio\n",
    "    X = MinMaxScaler().fit_transform(boston.data)\n",
    "    # Finalmente, generamos interacciones entre las diferentes características.\n",
    "    X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)\n",
    "    return X, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_extended_boston()\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 1 - k-Nearest Neighbors\n",
    "### Clasificación k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Usemos para empezar nuestro dataset *Forge*. Primero, separamos los datos en un set de training y de test para poder evaluar el rendimiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/victormac/anaconda3/envs/ks-sl/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
    }
   ],
   "source": [
    "import mglearn\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lo siguiente es importar e instanciar la clase. Aquí es donde podemos poner un número de vecinos, por ejemplo, 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalmente, entrenamos el modelo usando el juego de datos de entrenamiento. Esto implica almacenar el dataset para poder calcular los vecinos durante la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n                     weights='uniform')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predicciones sobre el juego de pruebas: [1 0 1 0 1 0 0]\n"
    }
   ],
   "source": [
    "print(\"Predicciones sobre el juego de pruebas:\", clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Precisión sobre el juego de pruebas: 0.86\n"
    }
   ],
   "source": [
    "print(\"Precisión sobre el juego de pruebas: {:.2f}\"\n",
    "      .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Análisis de KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se puede ilustrar la predicción para todos los puntos en el plano $xy$. Se usan colores en el plano de acuero con la clase predicha para el punto en cuestión. Eso permite ver la frontera de decisión y desarrollar una cierta intuición sobre el modelo en función del número de vecinos.\n",
    "\n",
    "En el siguiente código, se generan gráficas para valores de vecinos de 1, 3 y 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a7942f78e0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# the fit method returns the object self, so we can instantiate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# and fit in one line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # the fit method returns the object self, so we can instantiate\n",
    "    # and fit in one line\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(\n",
    "        clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} vecino(s)\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"característica 0\")\n",
    "    ax.set_ylabel(\"característica 1\")\n",
    "axes[0].legend(loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Pregunta**: ¿qué diferencias observas en la frontera de clasificación y qué puede decirse del uso de varios vecinos frente al uso de uno sólo?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Un sólo vecino hace que la frontera de decisión se ajuste mucho a los datos de entrenamiento. Si se incrementa el número de vecinos, la frontera se suaviza.\n",
    "Esto implica que con un número bajo de vecinos, el modelo es más complejo, y con un número alto, menos. Yendo a un extremo, si $k=n$, donde n es el núermo de muestras del juego de entrenamiento, todos los puntos tendrían el mismo número de vecions y la predicción sería siempre la mism: la clase más frecuente en el juego de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vamos a evaluar ahora la conexión entre complejidad y generalización usando un dataset real (Breast Cancer Dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target,\n",
    "    stratify=cancer.target, random_state=66)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# Probamos n_neighbors de 1 a 10\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Construimos el modelo\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Guardamos la precisión del training set\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # Guardamos la precisión de testing set (generalización)\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings,\n",
    "         training_accuracy, label=\"precisión training\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"precisión test\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "¿Reconoces las características de las curvas  de complejidad frente a precisión que vimos al principio? (Nótese que por el eje de ordenadas, la curva correspondiente al training set está invertida)\n",
    "\n",
    "**¿Qué numero de vecinos es el mejor para obtener el mejor rendimiento del modelo?**\n",
    "\n",
    "Como puede verse en la gráfica, obtenemos el mejor rendimiento en test para k=6, lo que nos da también la precisión que obtenemos en el dataset de training."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regresión k-NN\n",
    "También hay una variante de regresión de k-Nearest Neighbors. De nuevo, comparemos el uso de un solo vecino frente a tres para ver la variación de las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"396.748375pt\" version=\"1.1\" viewBox=\"0 0 607.820312 396.748375\" width=\"607.820312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 396.748375 \nL 607.820312 396.748375 \nL 607.820312 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 42.620312 359.192125 \nL 600.620312 359.192125 \nL 600.620312 33.032125 \nL 42.620312 33.032125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 170.448174 275.742374 \nL 170.448174 275.742374 \nL 170.448174 275.71607 \nL 190.572299 275.71607 \nL 190.572299 275.768677 \nL 170.448174 275.768677 \nL 170.448174 275.742374 \nz\n\" style=\"stroke:#000000;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 422.605047 182.729625 \nL 422.605047 182.729625 \nL 422.605047 182.755928 \nL 404.312603 182.755928 \nL 404.312603 182.703322 \nL 422.605047 182.703322 \nL 422.605047 182.729625 \nz\n\" style=\"stroke:#000000;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 448.126128 155.114826 \nL 448.126128 155.114826 \nL 448.126128 155.088523 \nL 457.747679 155.088523 \nL 457.747679 155.14113 \nL 448.126128 155.14113 \nL 448.126128 155.114826 \nz\n\" style=\"stroke:#000000;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0570756116\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.984609\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −3 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(49.613515 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.043069\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(138.671975 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.101529\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(227.730435 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"324.159989\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(320.978739 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.218449\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1 -->\n      <g transform=\"translate(410.037199 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"502.276909\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(499.095659 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"591.33537\" xlink:href=\"#m0570756116\" y=\"359.192125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3 -->\n      <g transform=\"translate(588.15412 373.790563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Feature -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     </defs>\n     <g transform=\"translate(302.348437 387.468687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"57.441406\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"118.964844\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"180.244141\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"219.453125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"282.832031\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"323.914062\" xlink:href=\"#DejaVuSans-101\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m57bd272f1a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"353.93148\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −3 -->\n      <g transform=\"translate(20.878125 357.730699)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"301.325028\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −2 -->\n      <g transform=\"translate(20.878125 305.124247)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"248.718577\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −1 -->\n      <g transform=\"translate(20.878125 252.517795)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"196.112125\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(29.257812 199.911344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"143.505673\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1 -->\n      <g transform=\"translate(29.257812 147.304892)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"90.899222\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2 -->\n      <g transform=\"translate(29.257812 94.698441)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.620312\" xlink:href=\"#m57bd272f1a\" y=\"38.29277\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 3 -->\n      <g transform=\"translate(29.257812 42.091989)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Target -->\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     </defs>\n     <g transform=\"translate(14.798437 212.483219)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"60.833984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"122.113281\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"163.210938\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"226.6875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"288.210938\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"LineCollection_1\">\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 190.572299 359.192125 \nL 190.572299 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 404.312603 359.192125 \nL 404.312603 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p9cd215a363)\" d=\"M 457.747679 359.192125 \nL 457.747679 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"me202a4cc4e\" style=\"stroke:#0000aa;\"/>\n    </defs>\n    <g clip-path=\"url(#p9cd215a363)\">\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"257.120406\" xlink:href=\"#me202a4cc4e\" y=\"219.691427\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"564.999522\" xlink:href=\"#me202a4cc4e\" y=\"178.687513\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"448.126128\" xlink:href=\"#me202a4cc4e\" y=\"155.114826\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"376.878225\" xlink:href=\"#me202a4cc4e\" y=\"194.272012\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"140.353288\" xlink:href=\"#me202a4cc4e\" y=\"269.116009\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"140.340399\" xlink:href=\"#me202a4cc4e\" y=\"326.153292\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"88.021631\" xlink:href=\"#me202a4cc4e\" y=\"276.458382\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"519.826491\" xlink:href=\"#me202a4cc4e\" y=\"117.50906\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"378.190873\" xlink:href=\"#me202a4cc4e\" y=\"143.488642\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"435.343729\" xlink:href=\"#me202a4cc4e\" y=\"184.035707\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"67.983949\" xlink:href=\"#me202a4cc4e\" y=\"251.864208\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"575.256676\" xlink:href=\"#me202a4cc4e\" y=\"155.133604\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"501.800967\" xlink:href=\"#me202a4cc4e\" y=\"156.436967\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"170.448174\" xlink:href=\"#me202a4cc4e\" y=\"275.742374\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"154.142918\" xlink:href=\"#me202a4cc4e\" y=\"284.124515\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"154.986948\" xlink:href=\"#me202a4cc4e\" y=\"243.719379\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"219.556683\" xlink:href=\"#me202a4cc4e\" y=\"191.667646\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"337.388607\" xlink:href=\"#me202a4cc4e\" y=\"223.853962\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"287.794758\" xlink:href=\"#me202a4cc4e\" y=\"224.579895\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"212.603121\" xlink:href=\"#me202a4cc4e\" y=\"214.046049\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"383.928668\" xlink:href=\"#me202a4cc4e\" y=\"184.65539\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"131.523259\" xlink:href=\"#me202a4cc4e\" y=\"255.278126\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"213.092324\" xlink:href=\"#me202a4cc4e\" y=\"176.490377\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"252.750338\" xlink:href=\"#me202a4cc4e\" y=\"190.979656\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"300.685952\" xlink:href=\"#me202a4cc4e\" y=\"247.99162\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"476.543981\" xlink:href=\"#me202a4cc4e\" y=\"145.244092\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"163.680446\" xlink:href=\"#me202a4cc4e\" y=\"255.796782\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"331.766172\" xlink:href=\"#me202a4cc4e\" y=\"159.393563\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"373.541784\" xlink:href=\"#me202a4cc4e\" y=\"173.146344\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"81.805422\" xlink:href=\"#me202a4cc4e\" y=\"246.431318\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"381.626663\" xlink:href=\"#me202a4cc4e\" y=\"194.256232\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"148.104304\" xlink:href=\"#me202a4cc4e\" y=\"305.839565\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"91.744977\" xlink:href=\"#me202a4cc4e\" y=\"221.053387\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"564.022317\" xlink:href=\"#me202a4cc4e\" y=\"115.251668\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"572.97082\" xlink:href=\"#me202a4cc4e\" y=\"150.400647\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"488.952347\" xlink:href=\"#me202a4cc4e\" y=\"97.388286\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"219.755208\" xlink:href=\"#me202a4cc4e\" y=\"191.139463\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"109.175777\" xlink:href=\"#me202a4cc4e\" y=\"270.551493\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"422.605047\" xlink:href=\"#me202a4cc4e\" y=\"182.729625\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"292.180429\" xlink:href=\"#me202a4cc4e\" y=\"191.16772\"/>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <defs>\n     <path d=\"M 0 -10 \nL -2.24514 -3.09017 \nL -9.510565 -3.09017 \nL -3.632713 1.18034 \nL -5.877853 8.09017 \nL -0 3.81966 \nL 5.877853 8.09017 \nL 3.632713 1.18034 \nL 9.510565 -3.09017 \nL 2.24514 -3.09017 \nz\n\" id=\"m9581fbf04f\" style=\"stroke:#50ff50;stroke-linejoin:bevel;\"/>\n    </defs>\n    <g clip-path=\"url(#p9cd215a363)\">\n     <use style=\"fill:#50ff50;stroke:#50ff50;stroke-linejoin:bevel;\" x=\"190.572299\" xlink:href=\"#m9581fbf04f\" y=\"353.93148\"/>\n     <use style=\"fill:#50ff50;stroke:#50ff50;stroke-linejoin:bevel;\" x=\"404.312603\" xlink:href=\"#m9581fbf04f\" y=\"353.93148\"/>\n     <use style=\"fill:#50ff50;stroke:#50ff50;stroke-linejoin:bevel;\" x=\"457.747679\" xlink:href=\"#m9581fbf04f\" y=\"353.93148\"/>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <defs>\n     <path d=\"M 0 -10 \nL -2.24514 -3.09017 \nL -9.510565 -3.09017 \nL -3.632713 1.18034 \nL -5.877853 8.09017 \nL -0 3.81966 \nL 5.877853 8.09017 \nL 3.632713 1.18034 \nL 9.510565 -3.09017 \nL 2.24514 -3.09017 \nz\n\" id=\"m3968aa9a8a\" style=\"stroke:#0000aa;stroke-linejoin:bevel;\"/>\n    </defs>\n    <g clip-path=\"url(#p9cd215a363)\">\n     <use style=\"fill:#0000aa;stroke:#0000aa;stroke-linejoin:bevel;\" x=\"190.572299\" xlink:href=\"#m3968aa9a8a\" y=\"275.742374\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;stroke-linejoin:bevel;\" x=\"404.312603\" xlink:href=\"#m3968aa9a8a\" y=\"182.729625\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;stroke-linejoin:bevel;\" x=\"457.747679\" xlink:href=\"#m3968aa9a8a\" y=\"155.114826\"/>\n    </g>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 42.620312 359.192125 \nL 42.620312 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 600.620312 359.192125 \nL 600.620312 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 42.620313 359.192125 \nL 600.620312 359.192125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 42.620313 33.032125 \nL 600.620312 33.032125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_10\">\n     <path d=\"M 100.420312 24.878125 \nL 444.4875 24.878125 \nQ 446.4875 24.878125 446.4875 22.878125 \nL 446.4875 9.2 \nQ 446.4875 7.2 444.4875 7.2 \nL 100.420312 7.2 \nQ 98.420312 7.2 98.420312 9.2 \nL 98.420312 22.878125 \nQ 98.420312 24.878125 100.420312 24.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"line2d_19\">\n     <g>\n      <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"112.420312\" xlink:href=\"#me202a4cc4e\" y=\"15.298437\"/>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- training data/target -->\n     <defs>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 25.390625 72.90625 \nL 33.6875 72.90625 \nL 8.296875 -9.28125 \nL 0 -9.28125 \nz\n\" id=\"DejaVuSans-47\"/>\n     </defs>\n     <g transform=\"translate(130.420312 18.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"260.546875\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"323.925781\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"387.402344\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"419.189453\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"482.666016\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"543.945312\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"583.154297\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"644.433594\" xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"678.125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"717.333984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"778.613281\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"819.710938\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"883.1875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"944.710938\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"line2d_21\">\n     <g>\n      <use style=\"fill:#50ff50;stroke:#50ff50;stroke-linejoin:bevel;\" x=\"258.810938\" xlink:href=\"#m9581fbf04f\" y=\"15.298437\"/>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- test data -->\n     <defs>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(276.810938 18.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"287.304688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"348.583984\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"387.792969\" xlink:href=\"#DejaVuSans-97\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\"/>\n    <g id=\"line2d_23\">\n     <g>\n      <use style=\"fill:#0000aa;stroke:#0000aa;stroke-linejoin:bevel;\" x=\"351.717188\" xlink:href=\"#m3968aa9a8a\" y=\"15.298437\"/>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- test prediction -->\n     <defs>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n     </defs>\n     <g transform=\"translate(369.717188 18.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"287.304688\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"328.386719\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"389.910156\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"453.386719\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"481.169922\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"536.150391\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"575.359375\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"603.142578\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"664.324219\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9cd215a363\">\n   <rect height=\"326.16\" width=\"558\" x=\"42.620312\" y=\"33.032125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 720x432 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La implementación de kNN para regresión en Scikit-learn es muy parecida a su equivalente de clasificación. Lo hacemos aquí para el *Wave* dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "\n",
    "# Partimos el dataset wave en training y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0)\n",
    "\n",
    "# Instanciamos el modelo y especificamos 3 vecinos\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# Ajustamos el modelo usando los objetivo y datos de training\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicciones sobre el test set:\\n\", reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "También podemos evaluar el modelo utilizando el método `score`, que para la regresión devuelve $R^2$ (el coeficiente de determinación, una medida de lo bueno que es un modelo de regresión que veremos en más detalle más adelante):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficiente de determinación del test set: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Análisis de KNeighborsRegressor\n",
    "\n",
    "Para establecer el análisis, vamos a hacer una predicción de todos los posibles valores que puede tener la característica $x$ (donde $x\\in[1,3000]$), y para ello creamos un dataset que tenga todos los puntos en una línea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# Crear 1,000 data points, igualmente espaciados entre -3 y 3\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # make predictions using 1, 3, or 9 neighbors\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"{} vecinos(s)\\n Train score: {:.2f} Test score: {:.2f}\".format(\n",
    "            n_neighbors, reg.score(X_train, y_train),\n",
    "            reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"Característica\")\n",
    "    ax.set_ylabel(\"Objetivo\")\n",
    "axes[0].legend([\"Predición modelo\", \"Training data/objetivo\",\n",
    "                \"Test data/objetivo\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como ejercicio adicional con kNNs, ábrase el fichero [kNNs-Exercise.ipynb](kNNs-Exercise.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprendizaje Supervisado con Scikit-Learn - Día 2"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 2 - Modelos lineales de regresión\n",
    "\\begin{align*}\n",
    "\\end{align*}\n",
    "A continuación, se muestra el gráfico del ajuste por regresión lineal de los datos del dataset *Wave*.  Lo mostramos para adelantar la discusión teórica sobre el modelo, más abajo aprenderemos cómo entrenar modelos lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "w[0]: 0.393906  b: -0.031804\n"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"429.896307pt\" version=\"1.1\" viewBox=\"0 0 460.8 429.896307\" width=\"460.8pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 429.896307 \nL 460.8 429.896307 \nL 460.8 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 7.2 416.817401 \nL 453.6 416.817401 \nL 453.6 10.999219 \nL 7.2 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 27.490909 416.817401 \nL 27.490909 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"meaf3bdd76c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.490909\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −3 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(20.119815 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 95.127273 416.817401 \nL 95.127273 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.127273\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(87.756179 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 162.763636 416.817401 \nL 162.763636 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"162.763636\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(155.392543 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 230.4 416.817401 \nL 230.4 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(227.21875 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 298.036364 416.817401 \nL 298.036364 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"298.036364\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1 -->\n      <g transform=\"translate(294.855114 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 365.672727 416.817401 \nL 365.672727 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"365.672727\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(362.491477 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 433.309091 416.817401 \nL 433.309091 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"433.309091\" xlink:href=\"#meaf3bdd76c\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3 -->\n      <g transform=\"translate(430.127841 228.506747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 416.817401 \nL 453.6 416.817401 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m819c49bccb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"416.817401\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −3 -->\n      <g transform=\"translate(208.657812 420.616619)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 349.181037 \nL 453.6 349.181037 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"349.181037\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −2 -->\n      <g transform=\"translate(208.657812 352.980256)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 281.544673 \nL 453.6 281.544673 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"281.544673\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −1 -->\n      <g transform=\"translate(208.657812 285.343892)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 213.90831 \nL 453.6 213.90831 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"213.90831\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(217.0375 217.707528)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 146.271946 \nL 453.6 146.271946 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"146.271946\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1 -->\n      <g transform=\"translate(217.0375 150.071165)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 78.635582 \nL 453.6 78.635582 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"78.635582\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2 -->\n      <g transform=\"translate(217.0375 82.434801)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pef2a52c145)\" d=\"M 7.2 10.999219 \nL 453.6 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.4\" xlink:href=\"#m819c49bccb\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 3 -->\n      <g transform=\"translate(217.0375 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#pef2a52c145)\" d=\"M 27.490909 295.986457 \nL 31.590083 294.37177 \nL 35.689256 292.757083 \nL 39.78843 291.142395 \nL 43.887603 289.527708 \nL 47.986777 287.913021 \nL 52.08595 286.298334 \nL 56.185124 284.683647 \nL 60.284298 283.068959 \nL 64.383471 281.454272 \nL 68.482645 279.839585 \nL 72.581818 278.224898 \nL 76.680992 276.61021 \nL 80.780165 274.995523 \nL 84.879339 273.380836 \nL 88.978512 271.766149 \nL 93.077686 270.151462 \nL 97.17686 268.536774 \nL 101.276033 266.922087 \nL 105.375207 265.3074 \nL 109.47438 263.692713 \nL 113.573554 262.078025 \nL 117.672727 260.463338 \nL 121.771901 258.848651 \nL 125.871074 257.233964 \nL 129.970248 255.619277 \nL 134.069421 254.004589 \nL 138.168595 252.389902 \nL 142.267769 250.775215 \nL 146.366942 249.160528 \nL 150.466116 247.545841 \nL 154.565289 245.931153 \nL 158.664463 244.316466 \nL 162.763636 242.701779 \nL 166.86281 241.087092 \nL 170.961983 239.472404 \nL 175.061157 237.857717 \nL 179.160331 236.24303 \nL 183.259504 234.628343 \nL 187.358678 233.013656 \nL 191.457851 231.398968 \nL 195.557025 229.784281 \nL 199.656198 228.169594 \nL 203.755372 226.554907 \nL 207.854545 224.940219 \nL 211.953719 223.325532 \nL 216.052893 221.710845 \nL 220.152066 220.096158 \nL 224.25124 218.481471 \nL 228.350413 216.866783 \nL 232.449587 215.252096 \nL 236.54876 213.637409 \nL 240.647934 212.022722 \nL 244.747107 210.408035 \nL 248.846281 208.793347 \nL 252.945455 207.17866 \nL 257.044628 205.563973 \nL 261.143802 203.949286 \nL 265.242975 202.334598 \nL 269.342149 200.719911 \nL 273.441322 199.105224 \nL 277.540496 197.490537 \nL 281.639669 195.87585 \nL 285.738843 194.261162 \nL 289.838017 192.646475 \nL 293.93719 191.031788 \nL 298.036364 189.417101 \nL 302.135537 187.802413 \nL 306.234711 186.187726 \nL 310.333884 184.573039 \nL 314.433058 182.958352 \nL 318.532231 181.343665 \nL 322.631405 179.728977 \nL 326.730579 178.11429 \nL 330.829752 176.499603 \nL 334.928926 174.884916 \nL 339.028099 173.270228 \nL 343.127273 171.655541 \nL 347.226446 170.040854 \nL 351.32562 168.426167 \nL 355.424793 166.81148 \nL 359.523967 165.196792 \nL 363.62314 163.582105 \nL 367.722314 161.967418 \nL 371.821488 160.352731 \nL 375.920661 158.738044 \nL 380.019835 157.123356 \nL 384.119008 155.508669 \nL 388.218182 153.893982 \nL 392.317355 152.279295 \nL 396.416529 150.664607 \nL 400.515702 149.04992 \nL 404.614876 147.435233 \nL 408.71405 145.820546 \nL 412.813223 144.205859 \nL 416.912397 142.591171 \nL 421.01157 140.976484 \nL 425.110744 139.361797 \nL 429.209917 137.74711 \nL 433.309091 136.132422 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m0d9a3d9cb9\" style=\"stroke:#0000aa;\"/>\n    </defs>\n    <g clip-path=\"url(#pef2a52c145)\">\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"179.486099\" xlink:href=\"#m0d9a3d9cb9\" y=\"293.768804\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"413.30806\" xlink:href=\"#m0d9a3d9cb9\" y=\"180.079366\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"324.54736\" xlink:href=\"#m0d9a3d9cb9\" y=\"204.592828\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"270.437407\" xlink:href=\"#m0d9a3d9cb9\" y=\"134.505804\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"90.80611\" xlink:href=\"#m0d9a3d9cb9\" y=\"303.212589\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"90.796322\" xlink:href=\"#m0d9a3d9cb9\" y=\"374.453185\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"51.062295\" xlink:href=\"#m0d9a3d9cb9\" y=\"261.333104\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"379.000938\" xlink:href=\"#m0d9a3d9cb9\" y=\"132.52825\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"271.43431\" xlink:href=\"#m0d9a3d9cb9\" y=\"194.115918\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"314.839635\" xlink:href=\"#m0d9a3d9cb9\" y=\"183.491186\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"35.844471\" xlink:href=\"#m0d9a3d9cb9\" y=\"246.811483\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"421.097962\" xlink:href=\"#m0d9a3d9cb9\" y=\"119.545051\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"365.311268\" xlink:href=\"#m0d9a3d9cb9\" y=\"141.277657\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"113.661981\" xlink:href=\"#m0d9a3d9cb9\" y=\"302.402475\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"101.278787\" xlink:href=\"#m0d9a3d9cb9\" y=\"300.285563\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"101.919794\" xlink:href=\"#m0d9a3d9cb9\" y=\"277.875971\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"150.957943\" xlink:href=\"#m0d9a3d9cb9\" y=\"236.019369\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"240.44661\" xlink:href=\"#m0d9a3d9cb9\" y=\"196.231957\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"202.782051\" xlink:href=\"#m0d9a3d9cb9\" y=\"298.883624\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"145.676989\" xlink:href=\"#m0d9a3d9cb9\" y=\"264.396791\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"275.791938\" xlink:href=\"#m0d9a3d9cb9\" y=\"148.807915\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"84.100054\" xlink:href=\"#m0d9a3d9cb9\" y=\"264.798525\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"146.048519\" xlink:href=\"#m0d9a3d9cb9\" y=\"225.982316\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"176.167206\" xlink:href=\"#m0d9a3d9cb9\" y=\"204.866012\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"212.572401\" xlink:href=\"#m0d9a3d9cb9\" y=\"239.999338\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"346.12959\" xlink:href=\"#m0d9a3d9cb9\" y=\"159.866815\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"108.52216\" xlink:href=\"#m0d9a3d9cb9\" y=\"289.62614\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"236.176594\" xlink:href=\"#m0d9a3d9cb9\" y=\"147.676643\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"267.903512\" xlink:href=\"#m0d9a3d9cb9\" y=\"169.387867\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"46.341331\" xlink:href=\"#m0d9a3d9cb9\" y=\"219.411881\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"274.043656\" xlink:href=\"#m0d9a3d9cb9\" y=\"262.702958\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"96.692699\" xlink:href=\"#m0d9a3d9cb9\" y=\"286.736617\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"53.890028\" xlink:href=\"#m0d9a3d9cb9\" y=\"270.509781\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"412.565913\" xlink:href=\"#m0d9a3d9cb9\" y=\"165.923095\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"419.361945\" xlink:href=\"#m0d9a3d9cb9\" y=\"149.598412\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"355.553251\" xlink:href=\"#m0d9a3d9cb9\" y=\"188.132228\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"151.108715\" xlink:href=\"#m0d9a3d9cb9\" y=\"227.173712\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"67.128029\" xlink:href=\"#m0d9a3d9cb9\" y=\"275.721683\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"305.165112\" xlink:href=\"#m0d9a3d9cb9\" y=\"158.944419\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"206.112794\" xlink:href=\"#m0d9a3d9cb9\" y=\"277.091821\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"77.016244\" xlink:href=\"#m0d9a3d9cb9\" y=\"329.655474\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"228.442702\" xlink:href=\"#m0d9a3d9cb9\" y=\"235.761328\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"41.446396\" xlink:href=\"#m0d9a3d9cb9\" y=\"244.150643\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"396.509661\" xlink:href=\"#m0d9a3d9cb9\" y=\"132.871227\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"132.508531\" xlink:href=\"#m0d9a3d9cb9\" y=\"264.737464\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"296.354498\" xlink:href=\"#m0d9a3d9cb9\" y=\"186.845417\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"153.988931\" xlink:href=\"#m0d9a3d9cb9\" y=\"215.643524\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"238.543968\" xlink:href=\"#m0d9a3d9cb9\" y=\"161.413032\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"249.355881\" xlink:href=\"#m0d9a3d9cb9\" y=\"197.717363\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"102.508208\" xlink:href=\"#m0d9a3d9cb9\" y=\"321.336481\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"420.96598\" xlink:href=\"#m0d9a3d9cb9\" y=\"164.438159\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"342.053902\" xlink:href=\"#m0d9a3d9cb9\" y=\"196.936625\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"408.756661\" xlink:href=\"#m0d9a3d9cb9\" y=\"145.202434\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"390.628117\" xlink:href=\"#m0d9a3d9cb9\" y=\"126.692466\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"270.129591\" xlink:href=\"#m0d9a3d9cb9\" y=\"169.800335\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"401.604235\" xlink:href=\"#m0d9a3d9cb9\" y=\"158.031041\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"63.402775\" xlink:href=\"#m0d9a3d9cb9\" y=\"330.519765\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"107.024318\" xlink:href=\"#m0d9a3d9cb9\" y=\"318.517799\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"45.844965\" xlink:href=\"#m0d9a3d9cb9\" y=\"284.068587\"/>\n     <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"159.515872\" xlink:href=\"#m0d9a3d9cb9\" y=\"247.139192\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 230.4 416.817401 \nL 230.4 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 453.6 416.817401 \nL 453.6 10.999219 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 7.2 213.90831 \nL 453.6 213.90831 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 7.2 10.999219 \nL 453.6 10.999219 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 350.157812 48.355469 \nL 446.6 48.355469 \nQ 448.6 48.355469 448.6 46.355469 \nL 448.6 17.999219 \nQ 448.6 15.999219 446.6 15.999219 \nL 350.157812 15.999219 \nQ 348.157812 15.999219 348.157812 17.999219 \nL 348.157812 46.355469 \nQ 348.157812 48.355469 350.157812 48.355469 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 352.157812 24.097656 \nL 372.157812 24.097656 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_15\">\n     <!-- model -->\n     <defs>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(380.157812 27.597656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"158.59375\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"222.070312\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"283.59375\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\"/>\n    <g id=\"line2d_34\">\n     <g>\n      <use style=\"fill:#0000aa;stroke:#0000aa;\" x=\"362.157812\" xlink:href=\"#m0d9a3d9cb9\" y=\"38.775781\"/>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- training data -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <g transform=\"translate(380.157812 42.275781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"260.546875\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"323.925781\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"387.402344\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"419.189453\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"482.666016\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"543.945312\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"583.154297\" xlink:href=\"#DejaVuSans-97\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pef2a52c145\">\n   <rect height=\"405.818182\" width=\"446.4\" x=\"7.2\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 576x576 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se puede ver que el corte de la línea coincide con $b$, y que la pendiente es $w_0$. Si se compara esta recta con lo que hemos pintado previamente para el regresor kNN, una línea parece una predicción demasiado restrictiva y que el detalle de los datos se pierde. En parte es cierto, y es una asunción muy fuerte el suponer que el objetivo es una combinación lineal de características.\n",
    "\n",
    "Pero no nos dejemos engañar por la visión unidimensional del modelo. **Para datasets con muchas características** los modelos lineales pueden ser muy potentes.\n",
    "\n",
    "Hay diferentes modelos lineales para la regresión. La diferencia está en:\n",
    "\n",
    "  - cómo se aprenden $w$ y $b$ a partir de los datos de entrenamiento\n",
    "  - cómo se controla la complejidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regresión lineal, alias Ordinary Least Squares (OLS)\n",
    "\n",
    "La regresión lineal OLS es el método más simple y clásico de regresión lineal. Se trata de buscar los parámetros $w$ (también llamado pesos o coeficientes) y $b$ (también llamado *offset* o *intercept*) que minimicen el error cuadrático medio entre predicción y objetivo. No tiene más parámetros, que implica sencillez, pero también menos capacidad para controlar la complejidad del modelo.\n",
    "\n",
    "Éste es el código que produce la gráfica que aparece más arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Hacemos un dataset tipo wave con 60 muestras\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "# Hacemos el split, con un random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Por último, instanciamos y entrenamos el modelo\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scikit-learn almacena siempre los datos derivados del entrenamiento de un modelo en atributos que terminan en guión bajo. En este caso, podemos consultar los pesos y el corte a través de las variables `coef_` y `intercept_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra ambas variables para el modelo que acabamos de entrenar\n",
    "print(\"lr.coef_:\", lr.coef_) #Así nos dice la pendiente de la recta\n",
    "print(\"lr.intercept_:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Echemos un vistazo al rendimiento en el training set y el test set a través de $R^{2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "#No quiero ver 100%, el modelo tiene que generalizar bien\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))\n",
    "#No son muy buenos datos, son un poco bajas y tiene pinta de ser un poco underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El $R^2$ de test no es demasiado bueno, pero ambos se parecen.\n",
    "\n",
    "Esto significa que probablemente estamos en una situación de *underfitting*. En este caso de regresión lineal, con una dimensión hay muy poco riesgo de hacer overfitting, ya que el modelo es muy restringido.\n",
    "\n",
    "Con datasets con más características, los modelos lineales son más potentes,  y como consecuencia hay un mayor riesgo de incurrir en *overfitting*. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Veamos cómo se comporta OLS sobre un dataset como Boston Housing, que tiene mayor dimensionalidad (106 características). La manera de hacerlo es igual que en una dimensión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# Cargamos el dataset con la herramienta de carga de Scikit-Learn\n",
    "X, y = mglearn.datasets.load_extended_boston()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos datasets de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "#el random state es como un seed, solo para que a todos nos salga lo mismo, en la realidad no lo usaremos\n",
    "\n",
    "# Entrenamos el modelo\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora mostramos el score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))\n",
    "# Con más datos nos salen mejores scores, pero ojo\" es muy alta el training y más baja en el Test\n",
    "# Es probable que estemos haciendo overfitting\n",
    "# Podríamos introducir parámetros para dar más pesos a determinadas características: es lo que hace Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$R^2$ es ahora bueno en el training set, pero mucho peor en el test set.\n",
    "\n",
    "La discrepancia en el valor de $R^2$ es una señal clara de que hay *overfitting*. Deberíamos buscar un modelo que nos permita algo de control sobre la complejidad."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regresión contraída, de Tikhonov, o *Ridge*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La regresión *Ridge* usa la misma fórmula que OLS, pero los coeficientes $w$ se eligen de forma que se ajusten a una limitación adicional más allá de ajustarse a los datos.\n",
    "\n",
    "Se persigue además que los diferentes $w_i$ sean lo más pequeños posible.\n",
    "\n",
    "**Pregunta: ¿qué puede significar esto intuitivamente?**\n",
    "\n",
    "Esto significa que cada característica debería tener el menor peso posible sobre el resultado final, que se traduce en una pendiente menor a la vez que ajustándose para hacer una predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Esta técnica es un ejemplo de lo que se llama en ML **Regularización**, que es justamente restringir un modelo para evitar el *overfitting*. En particular, *Ridge* realiza una regularización de norma 2 ($L2$).\n",
    "\n",
    "Veamos cómo funciona en el dataset Boston Housing con Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es una regresión lineal pero introduciendo un grado de control, regulación L2,\n",
    "# que lo hace es cargarse los pesos que son pequeños y dar más protagonismo a pesos grandes\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))\n",
    "#Como se ve es mejor el Test, aunque baje un poco el Train, generalizamos mejor entonces\n",
    "# Como en este dataset teníamos muchas caracteristicas,\n",
    "# este tipo es mejor, porque el modelo es menos complejo "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discutimos los resultados**\n",
    "\n",
    "Vemos que $R^2$ para el training set es más bajo que OLS, mientras que para test es más alto, lo cual es consistente con lo que estábamos esperando ya que antes teníamos una situación de sobreajuste. \n",
    "\n",
    "Ridge es un modelo más constreñido, así que tenemos menos posibilidad de sobreajuste. Aunque el rendimiento en el conjunto de aprendizaje sea peor, **generaliza mejor**.\n",
    "\n",
    "El parámetro de control del modelo por el cual elegimos el balance entre simplicidad y rendimiento en el training set se llama ***alpha***. En el caso anterior se usaba el valor por defecto, $\\alpha=1.0$.\n",
    "\n",
    "El valor óptimo de $\\alpha$ dependerá del dataset particular."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Ejercicio: vuelve a entrenar un Rigde sobre Boston Housing, pasando un valor de alpha = 10, y muestra los valores de $R^2$ para training y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(\n",
    "    ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(\n",
    "    ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Ejercicio: Haz lo mismo pasando un valor de alpha = 0.1, y muestra los valores de $R^2$ para training y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fd64f1341c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m print(\"Training set score: {:.2f}\".format(\n\u001b[1;32m      3\u001b[0m     ridge01.score(X_train, y_train)))\n\u001b[1;32m      4\u001b[0m print(\"Test set score: {:.2f}\".format(\n\u001b[1;32m      5\u001b[0m     ridge01.score(X_test, y_test)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(\n",
    "    ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(\n",
    "    ridge01.score(X_test, y_test)))\n",
    "# Si comparamos con el anterior, hemso conseguido un poco más de rendimiento\n",
    "# (mejor en el Test, predice mejor) reduciendo el valor de alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Pregunta: ¿qué funciona mejor y cómo podríamos intentar mejorarlo?**\n",
    "\n",
    "$\\alpha=0.1$ funciona mejor, y podríamos intentar decrementar `alpha` aún algo más para ganar en generalización. Lo que se observa claramente es que el parámetro $\\alpha$ tiene una correspondencia con la complejidad del modelo que hemos visto en la presentación. Métodos concretos para seleccionar el parámetro entrarían dentro del campo de la **evaluación y mejora de modelos**."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "También podemos tener una visión cualitativa más amplia si inspeccionamos cómo cambian los coeficientes con el valor de `alpha`. Recordemos que en Scikit-learn tenemos el valor de estos coeficientes en el atributo `coef_`.\n",
    "\n",
    "Pintamos en un gráfico los coeficientes para los tres valores de $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "\n",
    "plt.plot(lr.coef_, 'o', label=\"OLR\")\n",
    "plt.xlabel(\"Indice coef.\")\n",
    "plt.ylabel(\"Magnitud coef.\")\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()\n",
    "# A mayor alpha más cercan están de la línea,\n",
    "# dando aun más peso a determinadas carecterísticas respecto a los otros alphas\n",
    "# Teniendo alpha muy alto es más restringido y nos podemos cargar la predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discusión**\n",
    "\n",
    "El eje $x$ tiene las componentes del vector de coeficientes ($x=0$ es $w_0$, $x=100$ es $w_100$), y el eje $y$ tiene el valor numérico del coeficiente.\n",
    "\n",
    "Un $\\alpha$ más alto significa un modelo más restringido, así que esperamos que las magnitudes de los coeficientes sean menores. Para $\\alpha=10$, vemos que el valor de los coeficientes permanece mayormente en el intervalo $[-3,3]$. Para $\\alpha=1$ los coeficientes son lago más grandes, y para $\\alpha=0.1$ lo son aún más y se ve que muchos de sus datapoints corresponden con el valor de la regresión lineal (que sería $\\alpha=0$) y son tan grandes que se salen de la gráfica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Otra manera de entender la influencia de la regularización es fijar $\\alpha$ e ir cambiando la cantidad de datos en el training dataset. Eso es lo que puede verse en el gráfico que sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_ridge_n_samples()\n",
    "# Se ve que la Línea regresión necesita un mínimo de datos, mientras que el Ridge no.\n",
    "# Conclusión: Usaremos Ridge cuando no tengamos una gran cantidad de datos\n",
    "# Se ve que con más datos, baja el rendimiento del training"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discusión**\n",
    "\n",
    "Como esperábamos, $R^2$ para el traning set es más alto que para el testing set tanto para Ridge como para OLS. Ya que Ridge está regularizado, su $Rˆ2$ en training es más bajo que para OLS independientemente del tamaño del dataset.\n",
    "\n",
    "Sin embargo, su test score es mejor, en particular para datasets más pequeños. Para menos de 400 puntos OLS no aprende nada. En cuanto vamos incrementando la cantidad de datos, se ve que ambos modelos mejoran, y OLS alcanza el rendimiento del Ridge justo al final.\n",
    "\n",
    "La conclusión es que con datasets suficientemente grandes, la regularización pierde importancia, y que ambos Ridge y OLS tiene el mismo rendimiento.\n",
    "\n",
    "Otro aspecto interesante es que el rendimiento de entrenamiento decrece con el aumento de datos para la regresión lineal. Esto implica que cuantos más datos se añaden al modelo, más difícil es que se produzca sobreajuste o que se memoricen los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regresión LASSO (Least Absolute Shrinkage and Selection Operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso es una alternativa a la regresión contraída. Utiliza una técnica similar consistente e reducir los coeficientes a casi cero, pero utilizando regularización $L1$.\n",
    "\n",
    "Cuando se usa $L1$, algunos coeficientes se hacen directamente cero, que implica que algunos coeficientes son ignorados por completo por el modelo.\n",
    "\n",
    "Esto constituye de facto una manera de hacer selección de características, aumentando la interpretabilidad del modelo y poniendo de relieve las características más importantes del mismo.\n",
    "\n",
    "Vamos a aplicar la técnica LASSO al dataset de Boston Housing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta es una regulación de nivel 1 (L1), similar a Ridge, pero aún más drástica\n",
    "# Lo vamos a utilizar cuando tenemos la sospecha que algunas características son muy importantes\n",
    "# (y puede que lo sepamos por análisis descriptivos anteriores)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(\n",
    "    lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(\n",
    "    lasso.score(X_test, y_test)))\n",
    "\n",
    "# Suma las características que sean distintas de cero\n",
    "print(\"Características usadas:\", np.sum(lasso.coef_ != 0))\n",
    "\n",
    "# funciona muy muy mal y puede ser porque estamos utilizando solo 3 características de 106\n",
    "# habría que probar un valor de alpha diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discusión**\n",
    "\n",
    "Como puede verse, Lasso ha funcionado bastante mal en ambos sets de datos, lo cual indica que el modelo está subajustando. Esto puede verse porque sólo se han usado 4 características de 105.\n",
    "\n",
    "Al igual que Ridge, Lasso tiene un parámetro $\\alpha$ de regularización que controla cómo de rápido los coeficientes convergen a cero. En el ejemplo anterior, al no ser especificado, se está usando un valor por defecto $\\alpha=1.0$.\n",
    "\n",
    "Para reducir el subajuste, se decrece el valor de $\\alpha$. Cuando se hace esto también hay que incrementar el valor por defecto de `max_iter` (que por defecto es 1000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrementamos el valor de alpha a 0.01\n",
    "# Incrementamos el número de \"max_iter\",\n",
    "# De otra forma, el modelo nos advertirá de que deberíamos incrementarlo.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(\n",
    "    X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(\n",
    "    lasso001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\"\n",
    "      .format(lasso001.score(X_test, y_test)))\n",
    "print(\"Características usadas:\",\n",
    "      np.sum(lasso001.coef_ != 0))\n",
    "#Hay una mejora importante, y como se ve ha cogido más características"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discusión**\n",
    "\n",
    "Un `alpha` más bajo nos permite un ajuste más complejo, que funcionará mejor sobre los datasets de training y test, y el rendimiento es algo mejor que usando Ridge. Estamos usando 33 de 105 características, siendo también el modelo algo menos complicado de entender.\n",
    "\n",
    "Si hiciésemos `alpha` demasiado bajo, eliminaríamos el efecto de la regularización y acabaríamos sobreajustando, con un resultado en consecuencia muy similar al de `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con un alpha de 0001\n",
    "lasso0001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso0001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso0001.score(X_test, y_test)))\n",
    "print(\"Características usadas:\", np.sum(lasso0001.coef_ != 0))\n",
    "\n",
    "# Hay mejora en el test, pero el Train es más alto, pero tal vez demasiado, aún así es bueno\n",
    "# Dependerá de otras cosas qué elegir, como el coste computacional económica, por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Una vez más, podemos pintar los coeficientes de los modelos anteriores con valores distintos de `alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso.coef_, 's',\n",
    "         label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso001.coef_, '^',\n",
    "         label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso0001.coef_, 'v',\n",
    "         label=\"Lasso alpha=0.0001\")\n",
    "\n",
    "plt.plot(ridge01.coef_, 'o',\n",
    "         label=\"Ridge alpha=0.1\")\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"Indice del coeficiente\")\n",
    "plt.ylabel(\"Magnitud del coeficiente\")\n",
    "# Como se ve con valor 1, solo hay 3 características fuera de la línea."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Discusión**\n",
    "\n",
    "Para `alpha`=1 se ve que la mayoría de los coeficientes son cero, y que los cuatro restantes son pequeños. Al decrementar `alpha` tenemos la solución marcada con triángulos rojos, que hace que la mayoría de las características sean cero. Con `alpha`=0.0001 nos queda un modelo bastante desregularizado, con la mayoría de los coeficientes distintos de cero y de gran magnitud.\n",
    "\n",
    "El modelo Ridge con `alpha`=0.1 tiene un rendimiento similar al Lasso con `alpha`=0.01, pero con Ridge todos los coeficientes son distintos de cero.\n",
    "\n",
    "En la práctica, la regresión Ridge es la primera opción entre los dos. Sin embargo, si el número de características es alto y se espera que sólo algunas de ellas sean relevantes, Lasso puede ser una mejor elección.\n",
    "\n",
    "De la misma forma, si lo que queremos es tener un modelo fácil de interpretar, Lasso es la opción ya que sólo usa un subconjunto de las características. Scikit-learn da la clase [`ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html?highlight=elasticnet#sklearn.linear_model.ElasticNet) que combina ambos. En la práctica la combinación funciona mejor, al precio de tener que ajustar dos parámetros: uno para la regularización $L1$ y otro para la $L2$."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 3 - Modelos lineales de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{align*}\n",
    "\\end{align*} Para empezar, apliquemos los modelos `LogisticRegression` y `LinearSVC` al dataset modelo `forge`, y visualicemos el límite de decisión para ambos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4969847c83af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmglearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_forge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m for model, ax in zip([LinearSVC(max_iter=10000),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Importamos paquetes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Importamos forge dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for model, ax in zip([LinearSVC(max_iter=10000),\n",
    "                      LogisticRegression(\n",
    "                          solver='liblinear')], axes):\n",
    "    clf = model.fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(\n",
    "        clf, X, fill=False, eps=0.5,\n",
    "        ax=ax, alpha=.7)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(clf.__class__.__name__)\n",
    "    ax.set_xlabel(\"Característica 0\")\n",
    "    ax.set_ylabel(\"Característica 1\")\n",
    "axes[0].legend()\n",
    "#Se ve que hay dos outliers, pero el modelo funciona bien en general en los dos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Puede verse que el límite de decisión es una línea recta que separa ambas clases. Cualquier punto encima de la línea será clasificado como perteneciente a la clase 1, mientras que puntos por debajo lo serán como clase 0.\n",
    "\n",
    "Los dos límites son similares, y en ambos casos los algoritmos están utilizando regularización $L2$, que es lo mismo que hacía Ridge en el apartado anterior.\n",
    "\n",
    "El parámetro que determina la fuerza de regularización en ambos casos se llama $C$, donde valores altos de $C$ corresponden a una menor regularización. Es decir, con un valor alto de $C$ ambos modelos intentarán ajustarse a los datos de training lo mejor posible, mientras que con un valor bajo los modelos se centrarán en encontrar un vector coeficientes $w$ cercano a cero.\n",
    "\n",
    "El efecto de diferentes valores de C en `LinearSCV` puede verse en los siguientes tres gráficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_svc_regularization()\n",
    "#Vamos a cambair el parámetro C, que es un regularización L2\n",
    "# Si sube C, ajustamos más al Training entonces los pesos son más importantes y afectan más a la separación\n",
    "# si bajamos C, se reduce la importancia que tienen los pesos de las características"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El el gráfico de la izquierda, tenemos un valor de $C$ muy pequeño correspondiente a una alta regularización. El modelo fuertemente regularizado elige una linea relativamente horizontal, errando en la clasificación de 2 puntos.\n",
    "\n",
    "El gráfico central inclina la línea hacia el otro lado, y se ve que el modelo se enfoca más en los dos puntos incorrectamente clasificados.\n",
    "\n",
    "Finalmente, en el gráfico de la derecha, el valor alto de $C$ hace que el límite de decisión se incline mucho, clasificando correctamente todos los puntos de la clase 0. Uno de los puntos de la clase 1 permanece incorrectamente clasificado, pero no es posible hacerlo mejor con un límite lineal. Este último modelo está sobreajustando los datos de entrenamiento.\n",
    "\n",
    "Al igual que en el caso de regresión, los modelos de clasificación lineal pueden parecer muy limitados en espacios de bajas dimensiones. Sin embargo, son más potentes en dimensiones más altas y protegen bien contra el sobreajuste cuando se consideran más características.\n",
    "\n",
    "Veamos cómo se comporta la regresión logística en el dataset de cáncer de mama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target,\n",
    "    stratify=cancer.target, random_state=42) #stratify para equilibrar los con o sin cancer\n",
    "logreg = LogisticRegression(solver='liblinear').fit(\n",
    "    X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\"\n",
    "      .format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\"\n",
    "      .format(logreg.score(X_test, y_test)))\n",
    "# El rendimiento es muy bueno, pero de ambos, entonces habría que comprobar varias cosas con parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un valor de $C=1$ da un rendimiento bastante bueno, con un 95% de precisión en ambos datasets. Pero si ambos están muy próximos, es posible que estemos subajustando. Vamos a incrementar el valor de $C$ buscando un modelo con más flexibilidad hacia los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg100 = LogisticRegression(\n",
    "    solver='liblinear',C=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(\n",
    "    logreg100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(\n",
    "    logreg100.score(X_test, y_test)))\n",
    "\n",
    "# Es muy parecido, ha subido un poco, eso quiere decir que nos hemos perdido algo aprendiendo más del training"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Con $C=100$ tenemos más precisión en el dataset de entrenamiento, y también un poco más en el de test, lo que confirma nuestra intuición de que un modelo más complejo debería comportarse mejor.\n",
    "\n",
    "Podemos investigar también qué ocurre si usamos un modelo aún más regularizado que el suministrado por defecto, haciendo que $C=0.01$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con C=0.01 \n",
    "logreg001 = LogisticRegression(\n",
    "    solver='liblinear', C=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(\n",
    "    logreg001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(\n",
    "    logreg001.score(X_test, y_test)))\n",
    "# Es muy parecido, pero ha bajado un poco, también es lógico porque hemos dado menor importancia a los pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como era de esperar, moverse más en la escala de $C$ desde un modelo que ya desajustaba lo que hace es reducir la precisión con respecto a los valores de $C$ por defecto.\n",
    "\n",
    "Finalmente, echemos un vistazo al os coeficientes aprendidos por el modelo con tres valores diferentes de $C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
    "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
    "plt.xticks(range(cancer.data.shape[1]),\n",
    "           cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"Característica\")\n",
    "plt.ylabel(\"Magnitud del coeficiente\")\n",
    "plt.legend()\n",
    "\n",
    "# se ve que Texture error y Mean radius son dos características importantes para\n",
    "# predecir si una persona tiene cancer, y luego están\n",
    "# worst concavity, worst compactness, también influyen pero menos.\n",
    "# Si miramos a Mean perimeter, hay que tener cuidado!, porque cambiando el C, puede ser positivo o negativo,\n",
    "# es decir pueden decir que tiene cancer o no y esto influencia en el modelo.\n",
    "# Este modelo es menos interpretable, si lo que queremos interpretar mejor debemos ir\n",
    "# a una regularización L1 (porque se cargan características) con la que puedes interpretar más cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`LogisticRegression` aplica una regularización tipo $L2$ por defecto, y por lo tanto sus resultados son parecidos a los que se obtenían con la regresión Ridge más arriba. Una regularización más fuerte aproxima más los coeficientes a cero, aunque estos nunca llegan a anularse.\n",
    "\n",
    "Si se miran los puntos en el gráfico con más detalle, se ven un efecto interesante en el tercer coeficiente, `mean perimeter`. Para $C=100$ y $C=1$, el coeficiente es negativo mientras que para $C=0.001$ es positivo, con una magnitud que es incluso mayor que para $C=1$. \n",
    "\n",
    "Al interpretar un modelo como este, uno puede pensar que el coeficiente nos dice la clase a la que está asociada una característica. Por ejemplo, se podría pensar que grandes magnitudes de `texture error` están relacionadas con que una muestra sea maligna. Sin embargo, el cambio de signo `mean perimeter` significa que dependiendo del modelo en el que nos enfoquemos, un valor alto de `mean perimeter` podría ser tanto un indicativo de benigno como de maligno.\n",
    "\n",
    "La conclusión es que las interpretaciones de los coeficientes en los modelos lineales no pueden realizarse a la ligera.\n",
    "\n",
    "Si quisiésemos tener un modelo más fácilmente interpretable, una regularización de tipo $L1$ ayuda, ya que limita al modelo a usar sólo algunas características. He aquí un gráfico de los coeficientes y las precisiones para un modelo $L1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):\n",
    "    lr_l1 = LogisticRegression(\n",
    "        max_iter=100000, C=C, solver='liblinear', penalty=\"l1\"\n",
    "    ).fit(X_train, y_train)\n",
    "    print(\"Precisión (Training) para Logistic Reg. L1 con C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_train, y_train)))\n",
    "    print(\"Precisión (Test) para Logistic Reg. L1 con C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_test, y_test)))\n",
    "    plt.plot(lr_l1.coef_.T, marker, label=\"C={:.3f}\".format(C))\n",
    "\n",
    "plt.xticks(\n",
    "    range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.xlabel(\"Característica\")\n",
    "plt.ylabel(\"Magnitud del coeficiente\")\n",
    "\n",
    "#Aquí podemos ver más claramente las características que más afectan a la precisión, es mucho más interpretable\n",
    "\n",
    "plt.ylim(-5, 5)\n",
    "plt.legend(loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como puede verse, hay muchos paralelismos entre los modelos lineales de clasificación binaria y los de regresión. Como en la regresión la diferencia fundamental entre modelos es el parámetro de penalización, que influencia la regularización y si el modelo usa todas o sólo una parte de las características."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modelos lineales de clasificación multiclase\n",
    "\\begin{align*}\n",
    "\\end{align*}\n",
    "Muchos modelos de clasificación lineal sólo funcionan con clasificaciones binarias, y no extienden a clasificación multicategoría (la regresión logística es una excepción).\n",
    "\n",
    "Para poder extender modelos binarios a un escenario multiclase, una técnica empleada con frecuencia es realizar una serie de entrenamientos *one-vs-rest*. Con esta técnica, se entrena un modelo binario para cada clase frente al resto, resultando en tantos modelos binario como clases haya. Para hacer una predicción, tendrán que ejecutarse todos los clasificadores binarios sobre la muestra en cuestión. El clasificador que tenga el score más alto marca cuál es la clase devuelta como resultado de la predicción.\n",
    "\n",
    "![one-vs-rest](images/one-vs-rest.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como ya se ha mencionado en la presentación, la regresión logística multiclase es diferente matemáticamente de la aproximación *one-vs-rest*, pero también se obtiene como resultado  un vector de coeficientes y un término $b$ por clase, con lo que se usa el mismo métdo para hacer la predicción de un coeficiente.\n",
    "\n",
    "Vamos a aplicar la técnica *one-vs-rest* a un dataset sencillo con tres clases. Usamos aquí un dataset bidimensional, al que cada clase se obtiene a partir de datos de una distribución normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=42)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Característica 0\")\n",
    "plt.ylabel(\"Característica 1\")\n",
    "plt.legend([\"Clase 0\", \"Clase 1\", \"Clase 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Con estos datos, entrenamos un modelo `LinearSVC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo LinearSCV\n",
    "linear_svm = LinearSVC().fit(X, y)\n",
    "print(\"dimensiones coeficientes: \", linear_svm.coef_.shape)\n",
    "print(\"Dimensiones término b: \", linear_svm.intercept_.shape)\n",
    "# Nos muestra que hay tres hiperplanos para diferenciar los grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`coef_` tiene dimensiones (3,2), 3 filas y dos columnas, lo que significa que cada fila contieneel vector de coeficientes de cada clase, y las columnas el valor del coeficiente para una de las dos características presentes. El término `intercept` es un array unidimensional (vector), con la $b$ de cada clase.\n",
    "\n",
    "Visualicemos las lineas frontera para cada clasificador binario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "# Creamos puntos en una línea en el intervalo [-15, 15]\n",
    "line = np.linspace(-15, 15)\n",
    "\n",
    "# Iteramos para pintar las lineas con colores distintos\n",
    "for coef, intercept, color in zip(\n",
    "    linear_svm.coef_, linear_svm.intercept_, mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.ylim(-10, 15)\n",
    "plt.xlim(-10, 8)\n",
    "plt.xlabel(\"Característica 0\")\n",
    "plt.ylabel(\"Característica 1\")\n",
    "plt.legend(['Clase 0', 'Clase 1', 'Clase 2', 'Linea clase 0', 'Linea clase 1',\n",
    "            'Linea clase 2'], loc=(1.01, 0.3))\n",
    "# Se ven las fronteras de decisión de las clases"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Puede verse que las muestras de clase 0 están por encima de la línea de clase 0, que significa que están en el lado \"clase 0\" de este clasificador binario. Estas muestras también están por necima de la línea de la clase 2, que significa que están clasificadas como \"resto\" por el clasificador binario de la clase 2. Por último, también están a la izquierda de la línea de la clase 1, qe significa que el clasificador binario de la clase 1 también los clasifica como \"resto\".\n",
    "\n",
    "Cualquier punto en este área será clasificado como Clase 0 por el clasificador final pero, ¿qué ocurre con el triángulo en mitad de la gráfica? Los tres clasificadores clasifican las muestras en este área como \"resto\", así que la clase correspondiente a una muestra aquí será la que tenga el valor más alto en la fórmula de clasificación, que es la que corresponde a la línea de clase más cercana.\n",
    "\n",
    "Para ilustrarlo, hagamos la predicción para todos los puntos de este espacio bidimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_2d_classification(linear_svm, X, fill=True, alpha=.7)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "                                  mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.legend(['Clase 0', 'Clase 1', 'Clase 2', 'Linea clase 0', 'Linea clase 1',\n",
    "            'Linea clase 2'], loc=(1.01, 0.3))\n",
    "plt.xlabel(\"Característica 0\")\n",
    "plt.ylabel(\"Característica 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 4 - Clasificadores Naive Bayes\n",
    "\n",
    "\n",
    "Un clasificador Naive Bayes tipo Bernoulli cuenta con qué frecuencia las características de cada clase son distintas de cero. Para entenderlo bien, veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array X de 4x4 con ceros y unos aleatoriamente\n",
    "X = np.array([[0, 1, 0, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [0, 0, 0, 1],\n",
    "              [1, 0, 1, 0]])\n",
    "# Crear un array y de 1x4 con las etiquetas (ceros y unos)\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tenemos cuatro muestras con cuatro características binarias cada una de ellas. Hay dos clases, 0 y 1. Para la clase 0 (primera y tercera muestra) la primera característica es 0 veces, y distinta de cero ninguna, la segunda característica es 0 una vez y distinta de 0 otra, y así sucesivamente.\n",
    "\n",
    "El mismo tipo de conteo se realiza para las muestras en la segunda clase. Contar las entradas distintas de cero por clase tiene esta pinta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar tipo de características\n",
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # iterate over each class\n",
    "    # count (sum) entries of 1 per feature\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"Feature counts:\\n\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar BernoulliNB, instanciar y entrenar\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar una predicción\n",
    "print(clf.predict([[1,1,1,0]]))\n",
    "\n",
    "# Para números con datos binarios (0 y 1) es mejor Bernoulli, para textos(ej.SPAM) es mejor otros como Multinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para hacer una predicción, la muestra suministrada se compara con la estadística de cada una de las clases, y el resultado es la mejor correspondencia.\n",
    "\n",
    "En el caso de `MultinomialNB` y `GaussianNB`, utilizan parámetros estadísticos diferentes. `MultinomialNB` considera el valor medio de cada característica para cada clase, mientras que `GaussianNB` almacena el valor medio y la desviación estándar de cada característica para cada clase.\n",
    "\n",
    "Al hacer una predicción, tanto para `MultinomialNB` como para `BernoulliNB` llegamos a una fórmula de predicción que es similar a la de los modelos lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab 5 - Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construcción de árboles de decisión\n",
    "Usemos ahora el método `make_moons` de Scikit-Learn para ilustrar gráficamente con un dataset de más puntos la construcción de un árbol de decisión, que también nos ayudará a revelar algunas de sus características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_tree_progressive()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Se repite el particionado recursivo de datos hasta que cada región, que coincide con un hoja del árbol, sólo contiene una variable objetivo (una sola clase o un sólo valor de regresión).\n",
    "\n",
    "Para realizar una predicción sobre una nueva muestra, se mira en qué región cae. La predicción mayoritaria ahí es la que determina el valor de la predición. El mismo proceso se sigue si se recorre el árbol desde la raíz y yendo a izqda o derecha dependiendo del cumplimiento de la condición expresada en el nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Control de la precisión de los árboles de decisión\n",
    "\n",
    "Todo este proceso, como puede intuirse, conduce a la construcción de árboles que son complejos y que sobreajustan mucho los datos de entrenamiento. El hecho de que existan hojas puras indica que el árbol es 100% preciso sobre el training set: cada punto de datos del mismo es una hoja que contiene a la clase mayoritaria correcta. Este sobreajuste se apreciaba bien en la figura anterior (áreas verticales finas de una clase en mitad de un área más grande de la otra clase).\n",
    "\n",
    "El tipo de fronteras de decisión así configuradas no es de la clase que uno se esperaría encontrar; hay demasiado foco en outliers y poco en elaborar un borde con un buen grado de generalización.\n",
    "\n",
    "Dos de las estrategias más comunes para evitar el sobreajuste son:\n",
    "\n",
    " - **Pre-prunning**: consiste en parar anticipadamente la construcción del árbol, por ejemplo limitando la profundidad máxima del árbol, el número máximo de hojas, o requerir la presencia de un número mínimo de muestras en un nodo para poder seguir adelante.\n",
    " - **Post-prunning**, o simplemente **prunning**: consiste en construir el árbol completo, pero eliminar posteriormente nodos que contienen poca información.\n",
    "\n",
    "Los árboles de decisión se implementan en Scikit-Learn con las clases `DecisionTreeRegressor` y `DecisionTreeClassifier`. classes. Scikit-learn sólo implementa estrategias de pre-pruning.\n",
    "\n",
    "\n",
    "Vamos a echar un vistazo al efecto del pre-prunning en más detalle en nuestro dataset de cáncer de mama. En principio, usamos la configuración por defecto para construir el árbol completo, que implica su crecimiento hasta que todas las hojas son puras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar un DecisionTreeClassifier desde el módulo tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Cargar el Breast Cancer Dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Partir el dataset alrededor del target\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# Instanciar un modelo y entrenarlo\n",
    "tree = DecisionTreeClassifier(random_state = 42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluarlo\n",
    "print(\"Precisión en el training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "# Se ve que hace un overfitting total, entonces vamos a limitar esto haciendo un pre-running"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como esperábamos, la precisión sobre el training set es del 100%. Ya que todas las hojas son puras, el modelo ha memorizado todos los datos. La precisión sobre el test set es un poco peor que en los modelos lineales que ya hemos visto, en los que alcanzábamos alrededor del 95%.\n",
    "\n",
    "Si no restringiesemos la profundidad, el árbol se volvería innecesariamente profundo y complejo, y eso no generalizaría bien los datos. Si hacemos pre-prunning, pararemos el desarrollo del árbol antes de que los datos se memoricen.\n",
    "\n",
    "Una de las opciones que hemos comentado es limitar la profundidad máxima. Vamos a fijar el parámetro max_depth=4, haciendo que sólo se hagan cuatro decisiones. La precisión de entrenamiento bajará, sin duda, pero a cambio de un incremento de la precisión en test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0) #Aquí ponemos 4 árboles\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Precisión en el training set: {:.3f}\"\n",
    "      .format(tree.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\"\n",
    "      .format(tree.score(X_test, y_test)))\n",
    "\n",
    "# Parece que merece la pena aunque parezca poco, además que es bueno cortar el árbol"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Análisis de los árboles de decisión\n",
    "\n",
    "Podemos visualizar el árbol utilizando la función `export_graphviz` incluida en el módulo `tree`. Esta función graba el árbol en un fichero de tipo `.dot`, que es un formato texto para describir árboles.\n",
    "\n",
    "Usamos una opción para colorear los nodos para reflejar la clase mayoritaria en cada uno y le pasamos los nombres de clases y caracterísitcas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", \n",
    "                class_names=[\"maligno\", \"benigno\"],\n",
    "                feature_names=cancer.feature_names,\n",
    "                impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Por último, leemos el fichero y los visualizamos para representar el árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuev que instalar el paquete graphviz antes así en terminal: brew install graphviz\n",
    "import graphviz\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))\n",
    "\n",
    "# Se ve que se interpreta bien, pero cortariamos un poco más para que sean un poco más explicables\n",
    "# De cada decisión los TRue caen a la izquierda y los False a la derecha"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La visualización del árbol nos da una buena visión de cómo el algoritmo hace predicciones en detalle, y es además un buen ejemplo de funcionamiento de algoritmo de Machine Learning que puede ser explicado con facilidad a legos en la materia.\n",
    "\n",
    "Pero incluso con un límite de cuatro niveles de profundidad, el árbol puede volverse difícil de gestionar. Con 10 niveles, es prácticamente ininteligible. \n",
    "\n",
    "Un método de inspeccionar cómo está comportándose el árbol es visualizar la ruta que están siguiendo los datos. Si vamos hacia la derecha, vemos que worst radius <= 16.795 crea un nodo que contiene sólo 8 muestras benignas pero 134 malignas. De las 142 muestras que fueron para la ramificación derecha, casi todas ellas terminaron en una hoja a la derecha del todo (132).\n",
    "\n",
    "Si desde la raíz vamos hacia la izquierda, para worst radius > 16.795, acabamos con 25 malignas y 259 benignas. Casi todos las muestras benignas acaban en la segunda hoja de la derecha (254 muestras benignas), con al mayoría de las otras hojas con muy pocas muestras benignas."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importancias de las características\n",
    "\n",
    "En vez de mirar el árbol completo, que puede ser demasiado, hay algunas propiedades útiles que podemos sacar para resumir cómo está funcionando el árbol. La más usada es la llamada importancias de las características (*feature importance*), que puntúa cómo de importantes es cada característica para cada una de las decisiones que toma el árbol. Es un número $\\in[0,1]$ para cada característica, donde 0 significa \"no usada en absoluto\" y 1 significa \"predice perfectamente el objetivo\". Las importancias de las características siempre suman uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importancia de las características:\")\n",
    "print(tree.feature_importances_)\n",
    "# Nos dice la importancia de cada característica, a mayor numero, mayor importancia\n",
    "# Las que sean bajas, no quiere decir que no sean importantes,\n",
    "# sino que el árbol ha decidido que no la va a usar porque resume peor el tipo de decisión a tomar\n",
    "# Ojo esto siempre serán indicadores\n",
    "# Si en la Linear Regresión esta carecterística también es importante, entonces empezamos a valorar que sí."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Podemos visualizar estas importancias de manera similar a la que visualizábamos los coeficientes en los modelos lineales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(np.arange(n_features), \n",
    "             model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Importancia de la característica\")\n",
    "    plt.ylabel(\"Característica\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se ve, como se esperaba, que la característica que aparece en el nodo raíz (\"worst radius\") es de lejos la más importante. Esto confirma nuestas observación en el análisis del árbol que el primer nivel separa las diferentes clases bastante bien.\n",
    "\n",
    "Sin embargo, que una característica tenga una importancia relativamente baja no quiere decir que no sea informativa. Sólo significa que dicha característica no fue elegida por el árbol, seguramente porque hay otra característica que codifica la misma información.\n",
    "\n",
    "En contraste con los coeficientes de los modelos lineales, las importancias de las características son siempre positivas y no codifican de qué clase es indicativa una característica. La importancia de una característica nos dice que \"worst radius\" es importante, pero no nos dice si es indicativo de una muestra maligna o benigna. De hecho no existe una relación tan sencilla entre características y clases, tal y como puede verse en el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = mglearn.plots.plot_tree_not_monotone()\n",
    "display(tree)\n",
    "#Para comprobar si el dataset es monótono, para interpretarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Este gráfico muestra un dataset con dos características y dos clases. En este caso, toda la información está contenida en $x_1$, mientras que $x_2$ no se usa en absoluto. Pero la relación entre $x_1$ y la clase resultante no es monótona, en el sentido en que podamos decir que un valor elevado de $x_1$ significa clase 0, y uno bajo significa clase 1 o viceversa.\n",
    "\n",
    "Aunque la discusión aquí se ha centrado en árboles de decisión para clasificación, todo lo dicho es válido también para regresión, implementado en Scikit-Learn por la clase `DecisionTreeRegressor`. El uso y análisis es muy mimilar, con mención especial al hecho de que no se pueden hacer extrapolaciones para hacer predicciones fuera del rango de los datos.\n",
    "\n",
    "Echemos un vistazo a esto en más detalle usando un dataset de precios históricos de RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ram_prices = pd.read_csv(os.path.join(mglearn.datasets.DATA_PATH, \"ram_price.csv\"))\n",
    "\n",
    "plt.semilogy(ram_prices.date, ram_prices.price)\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Precio en $/Mbyte\")\n",
    "#Hay una tendencia clara"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nótese la escala logarítmica del eje de ordenadas. Cuando se grafica logarítmicamente, la relación entre año y precio en dólares/Mb parece lineal y relativamente sencilla de predecir (salvo algunas crestas).\n",
    "\n",
    "Hagamos una predicción para los años posteriores al 2000 usando los datos históricos hasta este punto, contando con la fecha como única característica. Comparararemos dos modelos sencillos: `DecisionTreeRegressor` y `LinearRegressor`, reescalando los precios logarítmicamente para tener una relación lineal. Esto no supone una diferencia en cuanto a `DecisionTreeRegressor` pero sí para `LinearRegression`. Una vez entrenados los modelos y hechas las predicciones, aplicamos un mapeo exponencial para deshacer la transformación logarítmica.\n",
    "\n",
    "Haremos predicciones sobre el dataset completo por razones de visualización, aunque para una evaluación cuantitativa deberíamos considerar sólo el dataset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Usamos datos históricos para predecir precios después del año 2000 \n",
    "data_train = ram_prices[ram_prices.date < 2000]\n",
    "data_test = ram_prices[ram_prices.date >= 2000]\n",
    "\n",
    "# Predecimos precios en base a fechas\n",
    "X_train = data_train.date[:, np.newaxis] # Lo convertimos en vector columna con newaxis\n",
    "# Usamos una transformación logarítmica para obtener\n",
    "# una relación más sencilla de los datos y el objetivo \n",
    "y_train = np.log(data_train.price) # Hacemos la transformación logarítmica\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=3\n",
    "                            ).fit(X_train, y_train)\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predecimos para todos los datos\n",
    "X_all = ram_prices.date[:, np.newaxis]\n",
    "\n",
    "pred_tree = tree.predict(X_all)\n",
    "pred_lr = linear_reg.predict(X_all)\n",
    "\n",
    "# Deshacemos la transformación logarítmica\n",
    "price_tree = np.exp(pred_tree)\n",
    "price_lr = np.exp(pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora, dibujamos  las predicciones para comparar los modelos con los datos de partida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(data_train.date,\n",
    "             data_train.price, label=\"Training data\")\n",
    "plt.semilogy(data_test.date,\n",
    "             data_test.price, label=\"Test data\")\n",
    "plt.semilogy(ram_prices.date,\n",
    "             price_tree, label=\"Predicción Árbol\")\n",
    "plt.semilogy(ram_prices.date,\n",
    "             price_lr, label=\"Predicción Lineal\")\n",
    "plt.legend()\n",
    "\n",
    "# El árbol predice distinto, peor aún así la regresión lineal predice mejor\n",
    "# Se ve que en el año 2000, el árbol se mantiene constante, como el árbol no tiene datos del rango más adelante\n",
    "# de 2000, no predice bien. Es decir si la variable está fuera de rango del entrenamiento,\n",
    "# es mal predicto el árbol, porqu no sabe tomar decisiones de cosas que no sabe.\n",
    "# Todo lo relacionado con tendencias, el árbol de decisión no es buena.\n",
    "# Tampoco es bueno el randomForest por lo mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La diferencia que puede apreciarse entre el Árbol de decisión y el modelo lineal es importante.\n",
    "\n",
    "El modelo lineal aproxima con una recta, como ya sabíamos que ocurriría, y la línea da una buena predicción de los datos de test omitiendo las variaciones de grano fino que ocurren en ambos datasets.\n",
    "\n",
    "El árbol de decisión por el contrrio hace una predicción cuasi-perfecta en el dataset de entrenamiento. Sin embargo, una vez abandona el intervalo para el cual tiene datos, reutiliza la predicción del último datapoint del intervalo conocido para emitir predicciones en el dataset de test. El árbol no es capaz de generar respuestas nuevas fuera de lo que ha podido ver en el dataset de training. Esta limitación es de aplicación en todos los modelos basados en árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprendizaje Supervisado con Scikit-Learn - Día 3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensembles de árboles de decisión\n",
    "\n",
    "### Análisis de los random forests\n",
    "\n",
    "Vamos a construir un random forest con cinco árboles sobre el dataset `two_moons` que vimos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Usa make moons con 100 muestras\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "\n",
    "# Haz el split test / training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y,random_state=42)\n",
    "\n",
    "# Instancia y entrena un random forest con 5 estimadores\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators=5, random_state=2)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Los arboles construidos como parte del random forest se almacenan en el atributo `estimators_`. \n",
    "\n",
    "Vamos a visualizar ahora las fronteras de decisión aprendidas por cada árbol, junto con la predicción agregada hecha por el forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora lo pintamos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "# ravel(): devuelve un array aplanado de elementos contiguos\n",
    "# Pasamos los árboles con el atributo _estimators_ a una \n",
    "# función visualizadora\n",
    "for i, (ax, tree) in enumerate(zip(axes.ravel(),\n",
    "                                   forest.estimators_)):\n",
    "    ax.set_title(\"Árbol {}\".format(i))\n",
    "    mglearn.plots.plot_tree_partition(\n",
    "        X_train, y_train, tree, ax=ax)\n",
    "    \n",
    "mglearn.plots.plot_2d_separator(\n",
    "    forest, X_train, fill=True, ax=axes[-1, -1], alpha=.4)\n",
    "axes[-1, -1].set_title(\"Random Forest\")\n",
    "mglearn.discrete_scatter(\n",
    "    X_train[:, 0], X_train[:, 1], y_train)\n",
    "\n",
    "# Vemso que las fronteras son diferentes y cómo se generan los árboles, en la vida real no se usan\n",
    "# 4 árboles sino cientos de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Puede verse con bastante claridad en los gráficos que la frontera de decisión aprendida por cada uno de los cinco árboles es bastante diferente. Cada uno de ellos comete errores ya que hay muestras de entrenamiento que no están incluidas en el dataset de entrenamiento del árbol en sí por efecto del bootstrapping.\n",
    "\n",
    "El random forest sobreajusta menos que cualquiera de los árboles individuales, y por lo tanto suministra una frontera de decisión mucho más intuitiva. En un ejemplo real utilizaremos muchos más árboles (cientos o miles), lo cual producirán una frontera de decisión mucho más suave."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pongamos un ejemplo más y construyamos una random forest de 100 árboles sobre el dataset de cancer de mama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos nuestro cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "\n",
    "#from sklearn.datasets import load_breast_cancer\n",
    "#cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "# Instanciamos y entrenamos un bosque con 100 estimadores\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Muestra las precisiones de los dos sets de training y test\n",
    "print(\"Precisión en el training set: {:.3f}\"\n",
    "      .format(forest.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\"\n",
    "      .format(forest.score(X_test, y_test)))\n",
    "\n",
    "# La predicción del test es muy buena de partida, tanto de training como del test,\n",
    "# entonces tendremos que tocar pocos parámetros\n",
    "# Si comparamos con la Regresión lineal(0,95), este está mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El random forest nos da una precisión del 97%, mejor que la de los modelos lineales o la de un solo decision tree, sin tener que optimizar ningún parámetro. Podríamos ajustar el parámetro `max_features` o aplicar pre-prunning tal y como hicimos para el árbol de decisión único. Sin embargo, los valores por defecto parecer que funcionan bastante bien.\n",
    "\n",
    "Al igual que el árbol de decisión, los random forests proporcionan importancia de características.  Éstas se calculan agregando las importancias de las características para todos los árboles del bosque. Lo habitual es que las importancias que suministra el random forest sean más fidedignas que las que suministra un único árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_feature_importances_cancer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5383cb10e09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_feature_importances_cancer' is not defined"
     ]
    }
   ],
   "source": [
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El random forest da una importancia distinta de cero a más caracteríscas que un único árbol, y al igual que éste, da mucha importancia a la característica *worst radius*. Sin embargo, elige *worst perimeter* como la característica más informativa de todas. La aleatoriedad introducida en la construcción del random forest obliga al algoritmo a considerar múltiples explicaciones, con el resultado de que el random forest tienen una perspectiva más amplia de los datos que un único árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Análisis de las Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Veamos un ejemplo de uso de `GradientBoostingClassifier` en el dataset de cáncer de mama. Por defecto, se usan 100 árboles de un máximo de tres niveles de profundidad y un learning rate de 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos GradientBoostingClassifier del mismo módulo ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Hacemos split train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "# Instanciamos y entrenamos el modelo\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "# Visualizamos las precisiones de ambos sets con 3 decimales\n",
    "print(\"Precisión en el training set: {:.3f}\"\n",
    "      .format(gbrt.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\"\n",
    "      .format(gbrt.score(X_test, y_test)))\n",
    "      \n",
    "#Sale igual que el Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La precisión en el training set indica que podemos estar sobreajustando. Para reducir este sobreajuste, podemos o bien aplicar un pre prunning más fuerte o bien bajar el parámetro learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenamos aplicando prunning\n",
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Precisión en el training set: {:.3f}\"\n",
    "      .format(gbrt.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\"\n",
    "      .format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "# Vemos que no hemos conseguido nada así, pero podría ser mejor para que el\n",
    "# traning no sea tan preciso y se pueda generalizar más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenamos modificando la tasa de aprendizaje\n",
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Precisión en el training set: {:.3f}\"\n",
    "      .format(gbrt.score(X_train, y_train)))\n",
    "print(\"PRecisión en el test set: {:.3f}\"\n",
    "      .format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "# Y también vemos que no hemos conseguido nada así"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ambos métodos de decremento de la complejidad del modelo reducen la precisión en el training set, como era de esperar. En este caso, bajar la profundidad máxima del árbol mejora bastante el modelo, mientras que bajar el learning rate solo mejora la generalización levemente.\n",
    "\n",
    "Como en los otros casos, vamos a ver cómo se están asignando las importancias de las características ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "plot_feature_importances_cancer(gbrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Podemos ver que la importancia de las características es similar a la de los random forests, aunque aquí se ve que gradient boosting ignora completamente algunas de ellas.\n",
    "\n",
    "Ya que tanto gradient boosting machines como random forests se comportan bien sobre tipos de datos parecidos, una aproximación tomada con frecuencia es probar primero un random forest, que es bastante robusto. Si el random forest funciona bien pero el tiempo que se tarda en hacer una predicción es crítico, o es importante exprimir al máximo la precisión en predicción del modelo, probar con gradient boosting suele ser de ayuda.\n",
    "\n",
    "Si se quiere aplicar gradient boosting a problemas en gran escala, puede merecer la pena investigar algo más el paquete xgboost y su interfaz Python, que es más rápido que la implementación de Scikit-Learn para muchos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kernelized Support Vector Machines\n",
    "### Modelos lineales con características no lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hemos visto que los modelos lineales pueden ser bastante limitados en espacios 2D, ya que las lineas e hiperplanos tienen una flexibilidad limitada. Una manera de hacer un modelo lineal más flexible, como hemos visto, es aplicar ingeniería de características añadiendo interacciones o procesamiento polinómico de las características de entrada.\n",
    "\n",
    "Echemos un vistazo al dataset sintético que usamos para analiza la importancia de las características previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(centers=4, random_state=8)\n",
    "y = y % 2\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un modelo lineal de clasificación puede sólo separar puntos usando una línea, y no será por tanto capaz de hacer un buen trabajo en este dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer una clasificación lineal sobre el dataset\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=10000).fit(X, y)\n",
    "\n",
    "mglearn.plots.plot_2d_separator(linear_svm, X)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "\n",
    "# La regresión lineal hace lo que puede y no es un modelo muy válido\n",
    "# porque la frontera de desición no clasifica nada"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hagamos una expansión de las características de entrada, añadiendo también el cuadrado de la característica 1 como nueva característica. En vez de representar cada muestra como un punto bidimensional (característica 0, característica 1), la representamos como un punto 3D (característica 0, característica 1, característica 2 = (característica 1)^2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos la primera característica elevada al cuadrado, para probar\n",
    "X_new = np.hstack([X, X[:, 1:] ** 2])\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "figure = plt.figure()\n",
    "# Visualizamos en 3D\n",
    "ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "# Pintamos todos los puntos con y==0, y luego con y == 1\n",
    "mask = y == 0\n",
    "ax.scatter(X_new[mask, 0], X_new[mask, 1], X_new[mask, 2], c='b',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.scatter(X_new[~mask, 0], X_new[~mask, 1], X_new[~mask, 2],\n",
    "           c='r', marker='^',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.set_xlabel(\"característica 0\")\n",
    "ax.set_ylabel(\"característica 1\")\n",
    "ax.set_zlabel(\"(característica 1)ˆ2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "En esta nueva representación de los datos sí es posible separar las dos clases usando un modelo lineal, la separación es un plano en tres dimensiones. Se puede confirmar esto haciendo un entrenamiento de un modelo lineal sobre el nuevo dataset aumentado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_3d = LinearSVC(max_iter=10000).fit(X_new, y)\n",
    "coef, intercept = linear_svm_3d.coef_.ravel(), linear_svm_3d.intercept_\n",
    "\n",
    "# show linear decision boundary\n",
    "figure = plt.figure()\n",
    "ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "xx = np.linspace(X_new[:, 0].min() - 2, X_new[:, 0].max() + 2, 50)\n",
    "yy = np.linspace(X_new[:, 1].min() - 2, X_new[:, 1].max() + 2, 50)\n",
    "\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "ZZ = (coef[0] * XX + coef[1] * YY + intercept) / -coef[2]\n",
    "ax.plot_surface(XX, YY, ZZ, rstride=8, cstride=8, alpha=0.3)\n",
    "ax.scatter(X_new[mask, 0], X_new[mask, 1], X_new[mask, 2], c='b',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.scatter(X_new[~mask, 0], X_new[~mask, 1],\n",
    "           X_new[~mask, 2], c='r', marker='^',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "\n",
    "ax.set_xlabel(\"Característica 0\")\n",
    "ax.set_ylabel(\"Característica 1\")\n",
    "ax.set_zlabel(\"(Característica 1)^2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Considerado en función de la características originales, el modelo lineal SVM ya no es en realidad lineal. No es una línea sino una elipse, como puede verse a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ = YY ** 2\n",
    "dec = linear_svm_3d.decision_function(\n",
    "    np.c_[XX.ravel(), YY.ravel(), ZZ.ravel()])\n",
    "plt.contourf(XX, YY, dec.reshape(XX.shape),\n",
    "             levels=[dec.min(), 0, dec.max()],\n",
    "             cmap=mglearn.cm2, alpha=0.5)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Característica 0\")\n",
    "plt.ylabel(\"Característica 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### El truco del Kernel\n",
    "La lección a a aprender aquí es que la adición de características no lineales a la representación de nuestros datos puede hacer que los modelos lineales sean muchos más potentes. Sin embargo, en muchas ocasiones no sabremos qué características tenemos que añadir, y añadir tantas como todas las interacciones posibles en, por ejemplo, un espacio de 100 dimensiones, es computacionalmente muy caro.\n",
    "\n",
    "Afortunadamente, como hemos visto en la teoría de las presentaciones, hay un truco matemático muy conveniente  que nos permite entrenar un clasificador en un espacio dimensional más alto sin la necesidad de calcular esa nueva representación de los datos. Esto es lo que hemos visto ya que se conoce con el nombre de *kernel trick*, y funciona calculando directamente la distancia (más concretamente, el producto escalar) de las muestras en la representación expandida de las características, sin tener que llegar a calcular nunca esta representación.\n",
    "\n",
    "Hay dos maneras de hacer el mapeo de los datos a un espacio dimensional más alto que son las más utilizadas con SMVs:\n",
    "\n",
    " - **Un kernel polinómico**, que computa todos los posibles polinomios hasta un grado dado de las características originales (tipo (característica 1)^2 * (característica 2)^5)\n",
    " - **Un kernel RBF (Radial Basis Function)**, también conocido como kernel Gaussiano. El kernel gaussiano es un poco más complicado de explicar (lo hemos intentado en el material de presentación del curso), ya que corresponde a un espacio de características de dimensión infinita. Una manera de explicar el kernel Gaussiano es decir que considera todos los posibles polinomios de todos los grados, pero que la importancia de las características decrece conforme crece el grado polinómico."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Análisis de Support Vector Machines\n",
    "\\begin{align*}\n",
    "\\end{align*}\n",
    "Durante el entrenamiento, SMV aprende cuán importante es cada uno de las muestras en la representación de la frontera de decisión entre las dos clases. Por norma general, sólo un subconjunto de las muestras de entrenamiento son importantes aquí: las que caen en el borde entre las dos clases, como ya hemos visto en la teoría. Éstas son las muestras que llamábamos vectores soporte y que dan a SVM su nombre.\n",
    "\n",
    "Cuando vamos a hacer la predicción de un nuevo punto, lo que hace el modelo es medir la distancia a cada uno de los vectores soporte. La clasificación se realiza basándose en esas distancias y la importancia de las características que se aprendió durante la fase de entrenamiento (almacenada en el atributo `dual_coef_` del modelo).\n",
    "\n",
    "Por defecto, la distancia entre las muestas se mide con el kernel Gaussiano:\n",
    "\n",
    "$k_rbf(x_1, x_2) = e^{\\gamma \\left\\Vert x_1 - x_2 \\right\\Vert ^ 2}$\n",
    "\n",
    "En esta ecuación, $x_1$ y $x_2$ son muestras, $\\left\\Vert x_1 - X-2 \\right\\Vert$ denota la distancia euclídea, y $\\gamma$ es un parámetro que controla la anchura del kernel Gaussiano.\n",
    "\n",
    "A continuación se muestra el resultado del entrenamiento de SVM en un dataset bidimensional (*Forge* dataset). La frontera de decisión se muestra en negro, y los vectores soporte están remarcados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos SVC desde el módulo svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Hacemos un dataset levemente modificado\n",
    "X, y = mglearn.tools.make_handcrafted_dataset()                                                                  \n",
    "svm = SVC(kernel='rbf', C=10, gamma=0.1).fit(X, y)\n",
    "\n",
    "# Instanciamos y entrenamos un SVC con RBF, C=10 y gamma=0.1\n",
    "mglearn.plots.plot_2d_separator(svm, X, eps=.5)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "# Pintamos los vectores soporte\n",
    "sv = svm.support_vectors_\n",
    "# Las etiquetas de clase de los vectores vienen dadas por el signo de dual_coef\n",
    "sv_labels = svm.dual_coef_.ravel() > 0\n",
    "mglearn.discrete_scatter(sv[:, 0], sv[:, 1],\n",
    "                         sv_labels, s=15,\n",
    "                         markeredgewidth=3)\n",
    "plt.xlabel(\"Característica 0\")\n",
    "plt.ylabel(\"Característica 1\")\n",
    "\n",
    "# Nos muestra una curva suave que nos muestra los bordes soportes, tiene buena pinta como clasifica"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "En este caso, SMV produce una curva suave. Hemos ajustado dos parámetros, $C$ y $\\gamma$, que vamos a ver ahora en detalle:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ajuste de los parámetros de SVM\n",
    "\n",
    "El parámetro $\\gamma$ es el que hemos mostrado en la fórmula anterior, y controla la anchura del kernel Gaussiano. Esto est básicamente determinar la escala de qué significa que dos puntos esté juntos. El parámetro $C$ es un parámetro de regularización, similar al utilizado en los modelos lineales, que limita la importancia de cada punto (y más específicamente, el valor `dual_coef_`).\n",
    "\n",
    "Veamos que ocurre cuando vamos variando estos parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos 6 subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "\n",
    "# Iteramos para valores de C=0.1, 1 y 1000 en filas, y gamma -1, 0, 1 en columnas\n",
    "for ax, C in zip(axes, [-1, 0, 3]):\n",
    "    for a, gamma in zip(ax, range(-1, 2)):\n",
    "        # Nos apoyamos en una función ya definida para pintar los SVMs\n",
    "        mglearn.plots.plot_svm(log_C=C, \n",
    "                               log_gamma=gamma, ax=a)\n",
    "        \n",
    "axes[0, 0].legend([\"Clase 0\", \"Clase 1\",\n",
    "                   \"Clase SV 0\", \"Clase SV 1\"],\n",
    "                  ncol=4, loc=(.9, 1.2))\n",
    "# En horizontal, vemos las variaciones desde un valor de gamma pequeño(tamaño del kernel) a grande\n",
    "# En vertical, vemos las variaciones con C (parámetro de regularización), arriba tenemos un modelo muy restringido\n",
    "# y abajo no"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yendo de izquierda a derecha, vamos incrementando el valor del parámetro $\\gamma$ de 0.1 a 10. Un $\\gamma$ pequeño implica un radio grande para el kernel Gaussiano, que significa que son muchos puntos los que se consideran en proximidad. Esto se refleja en fronteras de decisión más suaves a la izquierda, y más enfocadas en muestras concretas a medida que nos vamos moviendo a la derecha. Un valor bajo de $\\gamma$ significa que la frontera de decisión variará lentamente, lo cual genera un modelo de baja complejidad, mientras que un valor alto de gamma generará modelos más complejos.\n",
    "\n",
    "Yendo de arriba a abajo, incrementamos el valor del parámetro $C$ de 0.1 a 1000. Como en el caso de los modelos lineales, una $C$ pequeña implica un modelo muy restringido, donde cada punto de datos puede tener puede tener sólo una influencia muy limitada. Esto se puede arriba a la izquierda, donde la frontera de decisión parece casi lineal, con las muestras mal clasificadas apenas teniendo ninguna influencia sobre la línea. Al incrementar $C$, como ocurre en los gráficos de abajo, se permite que estos puntos tengan una influencia más fuerte sobre el modelo y esto provoca que la frontera de decisión se adapte para clasificarlos correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apliquemos ahora SVM con kernel RBF al Breast Cancer dataset. Por defecto, $C=1$ y $\\gamma = \\frac{1}{\\mathrm{n\\_features}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Partimos en test y training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "# Instanciamos y entrenamos un SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Mostramos las precisiones\n",
    "print(\"Precisión en el training set: {:.2f}\"\n",
    "      .format(svc.score(X_train, y_train)))\n",
    "print(\"Precisión en el test set: {:.2f}\"\n",
    "      .format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El modelo sobreajusta bastante, con una precisión perfecta en el training set y sólo un 63% de precisión en el test set. Aunque los modelos SVM se comportan muy bien, son muy sensibles al ajuste de los parámetros y al escalado de los datos. En particular, requieren que todas las características varíen dentro de una escala similar.\n",
    "\n",
    "Echemos un vistazo a los valores mínimos y máximos de cada característica, graficados en espacio logarítmico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos un boxplot para mostrarlos\n",
    "plt.boxplot(X_train, manage_ticks=False)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlabel(\"Índice de la característica\")\n",
    "plt.ylabel(\"Magnitud de la característica\")\n",
    "\n",
    "# Esto nso quiere decir que hay que hacer preprocesado, porque hay muchos tipos de magnitud,\n",
    "# y esto afecta mucho al SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A partir de este gráfico podemos ver que las características en el Breast Cancer dataset son de órdenes de magnitud diferentes. Esto, que ya puede ser problemático para otros modelos (por ejemplo, modelos lineales), es devastador para kernel SVMs. Veamos algunas maneras de tratar con este problema, alguna de las cuales ya hemos adelantado en clase:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocesado de datos para SVMs\n",
    "Una manera de resolver este problema es mediante el reescalado de cada característica, como ya se ha visto en otros ejercicios, para que todas permanezcan en el mismo rango de escala (hablamos también de esto en las [notas adicionales de clase](https://docs.google.com/document/d/1ywFwDW-M4g2Skt-gU0UQWsX6P5ITbvjTOuDl-eGchj8). Un método muy común utilizando en SVMs es escalar todas las características entre 0 y 1, lo que se puede hacer con el preprocesador `MinMaxScaler` de Scikit-Learn.\n",
    "\n",
    "Con el ánimo de ilustrar exactamente qué hace este preprocesador, lo hacemos a continuación manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el valor mínimo de cada característica en el training set\n",
    "min_on_training = X_train.min(axis=0)\n",
    "# Calculamos el rango de cada característica\n",
    "#(max - min) en el training set\n",
    "range_on_training = (X_train - min_on_training).max(axis=0)\n",
    "\n",
    "# Restamos el mínimo y dividimos por el rango\n",
    "# después, min=0 y max=1 para cada caracterísitca\n",
    "X_train_scaled = (X_train - min_on_training) / range_on_training\n",
    "print(\"Mínimo para cada característica\\n\",\n",
    "      X_train_scaled.min(axis=0))\n",
    "print(\"Máximo para cada característica\\n\",\n",
    "      X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la misma transformación en el test set,\n",
    "# usando el mínimo y el rango del training set. See Chapter 3 (unsupervised learning) for details.\n",
    "# usando el mínimo y el rango del training set.\n",
    "X_test_scaled = (X_test - min_on_training) / range_on_training"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Con estos cambios, probamos de nuevo a entrenar y evaluar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos y entrenamos un SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mostramos las precisiones\n",
    "print(\"Precisión en el training set: {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como puede verse, escalar los datos mejora enormemente los resultados. De hecho, ahora estamos en una situación de subajuste, donde ambos rendimientos de training y test son similares pero menos cercanos a 100%. Desde esta situación de partida, podemos intentar incrementar $C$ o $\\gamma$ para ajustar con un modelo más complejo.\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena svc on C=1000\n",
    "svc = SVC(C=1000,gamma='auto')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Muestra la precisión\n",
    "print(\"Precisión en el training set: {:.3f}\".format(\n",
    "    svc.score(X_train_scaled, y_train)))\n",
    "print(\"Precisión en el test set: {:.3f}\"\n",
    "      .format(svc.score(X_test_scaled, y_test)))\n",
    "# Se ve que ha funcionado muy bien el subir el C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ks-sl",
   "language": "python",
   "name": "ks-sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}