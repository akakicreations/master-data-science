{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "03-porting-to-spark.inclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63XxA4x8rOft",
        "colab_type": "text"
      },
      "source": [
        "# Porting an analysis from local to distributed\n",
        "\n",
        "<a href = \"http://yogen.io\"><img src=\"http://yogen.io/assets/logo.svg\" alt=\"yogen\" style=\"width: 200px; float: right;\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FrruESrOf1",
        "colab_type": "text"
      },
      "source": [
        "Now comes the opportunity to put in practice what we have just learned!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHout2S5rOf3",
        "colab_type": "text"
      },
      "source": [
        "### If you are running this notebook in Google Colab\n",
        "\n",
        "Copy the following to a code cell and run it. It will install and set up Spark for you.\n",
        "\n",
        "```python\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.uvigo.es/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar -xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark pyspark==2.4.6\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZkRsFu1rOf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b2e2395f-d0a2-4532-c178-ee3804da57b2"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.uvigo.es/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar -xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark pyspark==2.4.6\n",
        " \n",
        "import os\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        " \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 218.4MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 45.1MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDofDeT7rOgQ",
        "colab_type": "text"
      },
      "source": [
        "# Guided exercise\n",
        "\n",
        "Recreate the boxplot we did in the pandas section, in Spark!\n",
        "\n",
        "Since matplotlib boxplot needs all the data and that would be unfeasible with Big Data, we will calculate the quartiles ourselves.\n",
        "\n",
        "Once the analysis is ported, we will be able to run it on the whole historical series! You can find it at https://transtats.bts.gov (On time performance reporting carrier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSBS4h11rOgV",
        "colab_type": "text"
      },
      "source": [
        "##  Workflow\n",
        "\n",
        "The basic idea is the same that we applied in the Amadeus Challenge:\n",
        "\n",
        "* Build prototype with small data: in this section, we will be using `06-intro_to_pandas_practical.ipynb` as our already made prototype\n",
        "\n",
        "* Modify your prototype so that it works with Big Data: In this case, it means porting it to Spark\n",
        "\n",
        "* Test your \"Big Data\" prototype with small data: We will first test it with a sample locally, then upload it to a cluster and test it with Small Data.\n",
        "    * You can run your analyses building your own cluster and storage bucket in Google Cloud Storage. More in notebook #4!\n",
        "\n",
        "* Run your prototype with Big Data.\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDjPK28grOgb",
        "colab_type": "text"
      },
      "source": [
        "## Modify the prototype so that it works with Big Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYISd1FErOge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solkLIjarOgt",
        "colab_type": "text"
      },
      "source": [
        "## Read csv\n",
        "\n",
        "We'll use the `SparkSession.read.csv` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYGlBXmIrOgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d7c847f-b3ce-45ae-ca09-718064106112"
      },
      "source": [
        "df = spark.read.csv('On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2018_12.csv.gz', inferSchema=True, header=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Year: int, Quarter: int, Month: int, DayofMonth: int, DayOfWeek: int, FlightDate: timestamp, Reporting_Airline: string, DOT_ID_Reporting_Airline: int, IATA_CODE_Reporting_Airline: string, Tail_Number: string, Flight_Number_Reporting_Airline: int, OriginAirportID: int, OriginAirportSeqID: int, OriginCityMarketID: int, Origin: string, OriginCityName: string, OriginState: string, OriginStateFips: int, OriginStateName: string, OriginWac: int, DestAirportID: int, DestAirportSeqID: int, DestCityMarketID: int, Dest: string, DestCityName: string, DestState: string, DestStateFips: int, DestStateName: string, DestWac: int, CRSDepTime: int, DepTime: int, DepDelay: double, DepDelayMinutes: double, DepDel15: double, DepartureDelayGroups: int, DepTimeBlk: string, TaxiOut: double, WheelsOff: int, WheelsOn: int, TaxiIn: double, CRSArrTime: int, ArrTime: int, ArrDelay: double, ArrDelayMinutes: double, ArrDel15: double, ArrivalDelayGroups: int, ArrTimeBlk: string, Cancelled: double, CancellationCode: string, Diverted: double, CRSElapsedTime: double, ActualElapsedTime: double, AirTime: double, Flights: double, Distance: double, DistanceGroup: int, CarrierDelay: double, WeatherDelay: double, NASDelay: double, SecurityDelay: double, LateAircraftDelay: double, FirstDepTime: int, TotalAddGTime: double, LongestAddGTime: double, DivAirportLandings: int, DivReachedDest: double, DivActualElapsedTime: double, DivArrDelay: double, DivDistance: double, Div1Airport: string, Div1AirportID: int, Div1AirportSeqID: int, Div1WheelsOn: int, Div1TotalGTime: double, Div1LongestGTime: double, Div1WheelsOff: int, Div1TailNum: string, Div2Airport: string, Div2AirportID: int, Div2AirportSeqID: int, Div2WheelsOn: int, Div2TotalGTime: double, Div2LongestGTime: double, Div2WheelsOff: int, Div2TailNum: string, Div3Airport: string, Div3AirportID: string, Div3AirportSeqID: string, Div3WheelsOn: string, Div3TotalGTime: string, Div3LongestGTime: string, Div3WheelsOff: string, Div3TailNum: string, Div4Airport: string, Div4AirportID: string, Div4AirportSeqID: string, Div4WheelsOn: string, Div4TotalGTime: string, Div4LongestGTime: string, Div4WheelsOff: string, Div4TailNum: string, Div5Airport: string, Div5AirportID: string, Div5AirportSeqID: string, Div5WheelsOn: string, Div5TotalGTime: string, Div5LongestGTime: string, Div5WheelsOff: string, Div5TailNum: string, _c109: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMWe3VzdvENm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "662e973b-d691-4820-ff7e-330352b7567c"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Quarter: integer (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            " |-- DayofMonth: integer (nullable = true)\n",
            " |-- DayOfWeek: integer (nullable = true)\n",
            " |-- FlightDate: timestamp (nullable = true)\n",
            " |-- Reporting_Airline: string (nullable = true)\n",
            " |-- DOT_ID_Reporting_Airline: integer (nullable = true)\n",
            " |-- IATA_CODE_Reporting_Airline: string (nullable = true)\n",
            " |-- Tail_Number: string (nullable = true)\n",
            " |-- Flight_Number_Reporting_Airline: integer (nullable = true)\n",
            " |-- OriginAirportID: integer (nullable = true)\n",
            " |-- OriginAirportSeqID: integer (nullable = true)\n",
            " |-- OriginCityMarketID: integer (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            " |-- OriginCityName: string (nullable = true)\n",
            " |-- OriginState: string (nullable = true)\n",
            " |-- OriginStateFips: integer (nullable = true)\n",
            " |-- OriginStateName: string (nullable = true)\n",
            " |-- OriginWac: integer (nullable = true)\n",
            " |-- DestAirportID: integer (nullable = true)\n",
            " |-- DestAirportSeqID: integer (nullable = true)\n",
            " |-- DestCityMarketID: integer (nullable = true)\n",
            " |-- Dest: string (nullable = true)\n",
            " |-- DestCityName: string (nullable = true)\n",
            " |-- DestState: string (nullable = true)\n",
            " |-- DestStateFips: integer (nullable = true)\n",
            " |-- DestStateName: string (nullable = true)\n",
            " |-- DestWac: integer (nullable = true)\n",
            " |-- CRSDepTime: integer (nullable = true)\n",
            " |-- DepTime: integer (nullable = true)\n",
            " |-- DepDelay: double (nullable = true)\n",
            " |-- DepDelayMinutes: double (nullable = true)\n",
            " |-- DepDel15: double (nullable = true)\n",
            " |-- DepartureDelayGroups: integer (nullable = true)\n",
            " |-- DepTimeBlk: string (nullable = true)\n",
            " |-- TaxiOut: double (nullable = true)\n",
            " |-- WheelsOff: integer (nullable = true)\n",
            " |-- WheelsOn: integer (nullable = true)\n",
            " |-- TaxiIn: double (nullable = true)\n",
            " |-- CRSArrTime: integer (nullable = true)\n",
            " |-- ArrTime: integer (nullable = true)\n",
            " |-- ArrDelay: double (nullable = true)\n",
            " |-- ArrDelayMinutes: double (nullable = true)\n",
            " |-- ArrDel15: double (nullable = true)\n",
            " |-- ArrivalDelayGroups: integer (nullable = true)\n",
            " |-- ArrTimeBlk: string (nullable = true)\n",
            " |-- Cancelled: double (nullable = true)\n",
            " |-- CancellationCode: string (nullable = true)\n",
            " |-- Diverted: double (nullable = true)\n",
            " |-- CRSElapsedTime: double (nullable = true)\n",
            " |-- ActualElapsedTime: double (nullable = true)\n",
            " |-- AirTime: double (nullable = true)\n",
            " |-- Flights: double (nullable = true)\n",
            " |-- Distance: double (nullable = true)\n",
            " |-- DistanceGroup: integer (nullable = true)\n",
            " |-- CarrierDelay: double (nullable = true)\n",
            " |-- WeatherDelay: double (nullable = true)\n",
            " |-- NASDelay: double (nullable = true)\n",
            " |-- SecurityDelay: double (nullable = true)\n",
            " |-- LateAircraftDelay: double (nullable = true)\n",
            " |-- FirstDepTime: integer (nullable = true)\n",
            " |-- TotalAddGTime: double (nullable = true)\n",
            " |-- LongestAddGTime: double (nullable = true)\n",
            " |-- DivAirportLandings: integer (nullable = true)\n",
            " |-- DivReachedDest: double (nullable = true)\n",
            " |-- DivActualElapsedTime: double (nullable = true)\n",
            " |-- DivArrDelay: double (nullable = true)\n",
            " |-- DivDistance: double (nullable = true)\n",
            " |-- Div1Airport: string (nullable = true)\n",
            " |-- Div1AirportID: integer (nullable = true)\n",
            " |-- Div1AirportSeqID: integer (nullable = true)\n",
            " |-- Div1WheelsOn: integer (nullable = true)\n",
            " |-- Div1TotalGTime: double (nullable = true)\n",
            " |-- Div1LongestGTime: double (nullable = true)\n",
            " |-- Div1WheelsOff: integer (nullable = true)\n",
            " |-- Div1TailNum: string (nullable = true)\n",
            " |-- Div2Airport: string (nullable = true)\n",
            " |-- Div2AirportID: integer (nullable = true)\n",
            " |-- Div2AirportSeqID: integer (nullable = true)\n",
            " |-- Div2WheelsOn: integer (nullable = true)\n",
            " |-- Div2TotalGTime: double (nullable = true)\n",
            " |-- Div2LongestGTime: double (nullable = true)\n",
            " |-- Div2WheelsOff: integer (nullable = true)\n",
            " |-- Div2TailNum: string (nullable = true)\n",
            " |-- Div3Airport: string (nullable = true)\n",
            " |-- Div3AirportID: string (nullable = true)\n",
            " |-- Div3AirportSeqID: string (nullable = true)\n",
            " |-- Div3WheelsOn: string (nullable = true)\n",
            " |-- Div3TotalGTime: string (nullable = true)\n",
            " |-- Div3LongestGTime: string (nullable = true)\n",
            " |-- Div3WheelsOff: string (nullable = true)\n",
            " |-- Div3TailNum: string (nullable = true)\n",
            " |-- Div4Airport: string (nullable = true)\n",
            " |-- Div4AirportID: string (nullable = true)\n",
            " |-- Div4AirportSeqID: string (nullable = true)\n",
            " |-- Div4WheelsOn: string (nullable = true)\n",
            " |-- Div4TotalGTime: string (nullable = true)\n",
            " |-- Div4LongestGTime: string (nullable = true)\n",
            " |-- Div4WheelsOff: string (nullable = true)\n",
            " |-- Div4TailNum: string (nullable = true)\n",
            " |-- Div5Airport: string (nullable = true)\n",
            " |-- Div5AirportID: string (nullable = true)\n",
            " |-- Div5AirportSeqID: string (nullable = true)\n",
            " |-- Div5WheelsOn: string (nullable = true)\n",
            " |-- Div5TotalGTime: string (nullable = true)\n",
            " |-- Div5LongestGTime: string (nullable = true)\n",
            " |-- Div5WheelsOff: string (nullable = true)\n",
            " |-- Div5TailNum: string (nullable = true)\n",
            " |-- _c109: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVQH0LdJrOhM",
        "colab_type": "text"
      },
      "source": [
        "## Select relevant columns\n",
        "\n",
        "Literally the same syntax as Pandas!\n",
        "\n",
        "```python\n",
        "df = df[['FlightDate', 'DayOfWeek', 'Reporting_Airline', 'Tail_Number', 'Flight_Number_Reporting_Airline', 'Origin', \n",
        "                'OriginCityName', 'OriginStateName', 'Dest', 'DestCityName', 'DestStateName',\n",
        "                'DepTime', 'DepDelay', 'AirTime', 'Distance']]\n",
        "                \n",
        "\n",
        "df\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2Ha1dQq5rOhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2749806c-6bd6-4fd8-92b7-3975ae1a7802"
      },
      "source": [
        "df = df[['FlightDate', 'DayOfWeek', 'Reporting_Airline', 'Tail_Number', 'Flight_Number_Reporting_Airline', 'Origin', \n",
        "                'OriginCityName', 'OriginStateName', 'Dest', 'DestCityName', 'DestStateName',\n",
        "                'DepTime', 'DepDelay', 'AirTime', 'Distance']]\n",
        " \n",
        " \n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[FlightDate: timestamp, DayOfWeek: int, Reporting_Airline: string, Tail_Number: string, Flight_Number_Reporting_Airline: int, Origin: string, OriginCityName: string, OriginStateName: string, Dest: string, DestCityName: string, DestStateName: string, DepTime: int, DepDelay: double, AirTime: double, Distance: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7HWO8u2rOhk",
        "colab_type": "text"
      },
      "source": [
        "### Extract \"Hour\" variable\n",
        "\n",
        "The DepTimes have been inferred to be ints. We need them as ints, representing each o fthe 24 hours in a day.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNfAB5_JrOhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e70da51f-a6cb-4cdf-c283-f977bbfb8430"
      },
      "source": [
        "df[['DepTime']].show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|DepTime|\n",
            "+-------+\n",
            "|   1048|\n",
            "|    638|\n",
            "|   1710|\n",
            "|   1318|\n",
            "|    953|\n",
            "|   1646|\n",
            "|   1813|\n",
            "|   1450|\n",
            "|    953|\n",
            "|   1219|\n",
            "+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ5KNo2BwhXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77dd7dde-f194-46e6-da8d-9b2c4c706d36"
      },
      "source": [
        "1048 // 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPPqp_i2wuwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "e16ab51c-12f8-4223-df68-35cac038ec4f"
      },
      "source": [
        "df.select(df['DepTime'] // 100 ).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-004fffbbcb5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DepTime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'Column' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKuG7Ja2wzqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "7cf259b9-c410-422e-81fe-71df6f7491b2"
      },
      "source": [
        "from pyspark.sql import types\n",
        "\n",
        "df2 = df.select('*',\n",
        "                (df['DepTime'] / 100).cast(types.IntegerType()).alias('Hour'))\n",
        "\n",
        "df2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+---------+-----------------+-----------+-------------------------------+------+--------------+---------------+----+------------+-------------+-------+--------+-------+--------+----+\n",
            "|         FlightDate|DayOfWeek|Reporting_Airline|Tail_Number|Flight_Number_Reporting_Airline|Origin|OriginCityName|OriginStateName|Dest|DestCityName|DestStateName|DepTime|DepDelay|AirTime|Distance|Hour|\n",
            "+-------------------+---------+-----------------+-----------+-------------------------------+------+--------------+---------------+----+------------+-------------+-------+--------+-------+--------+----+\n",
            "|2018-12-25 00:00:00|        2|               WN|     N566WN|                           1823|   OAK|   Oakland, CA|     California| GEG| Spokane, WA|   Washington|   1048|    18.0|  111.0|   723.0|  10|\n",
            "|2018-12-25 00:00:00|        2|               WN|     N562WN|                            982|   OAK|   Oakland, CA|     California| HOU| Houston, TX|        Texas|    638|    -2.0|  204.0|  1642.0|   6|\n",
            "|2018-12-25 00:00:00|        2|               WN|     N8611F|                           1562|   OAK|   Oakland, CA|     California| HOU| Houston, TX|        Texas|   1710|     0.0|  207.0|  1642.0|  17|\n",
            "|2018-12-25 00:00:00|        2|               WN|     N7721E|                           1687|   OAK|   Oakland, CA|     California| HOU| Houston, TX|        Texas|   1318|    -2.0|  204.0|  1642.0|  13|\n",
            "|2018-12-25 00:00:00|        2|               WN|     N218WN|                           1877|   OAK|   Oakland, CA|     California| HOU| Houston, TX|        Texas|    953|    -2.0|  205.0|  1642.0|   9|\n",
            "+-------------------+---------+-----------------+-----------+-------------------------------+------+--------------+---------------+----+------------+-------------+-------+--------+-------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euz1m4tZrOhz",
        "colab_type": "text"
      },
      "source": [
        "## Generate the relative distributions\n",
        "\n",
        "In order to be able to handle the data, we need to reduce its dimensionality. Since we want to describe a discrete distribution, we can just count how many values of each level of the 'DepDelay' variable we find for each hour (24 different discrete distributions). We also want the totals in order to do the relative distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjo6ZYdrOh4",
        "colab_type": "text"
      },
      "source": [
        "### Totals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c3a8yaPrOh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "797af617-8a53-4d9f-dfe9-0e96e48b96f0"
      },
      "source": [
        "%%time\n",
        "totals_per_hour = df2.groupBy('Hour').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.1 ms, sys: 125 µs, total: 2.23 ms\n",
            "Wall time: 22.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjV7Ey-ce-t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "af06bd12-0487-4f80-d11d-c546cbaca36e"
      },
      "source": [
        "%%time\n",
        "totals_per_hour.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+\n",
            "|Hour|count|\n",
            "+----+-----+\n",
            "|  12|36925|\n",
            "|  22|15646|\n",
            "|null| 6526|\n",
            "|   1|  846|\n",
            "|  13|33163|\n",
            "+----+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "CPU times: user 1.94 ms, sys: 94 µs, total: 2.03 ms\n",
            "Wall time: 4.46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeRQkFwMfkSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "bf47e2b9-68ef-49fa-f5e0-907e3f9aa8b2"
      },
      "source": [
        "df2[['Hour', 'DepDelay']].show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------+\n",
            "|Hour|DepDelay|\n",
            "+----+--------+\n",
            "|  10|    18.0|\n",
            "|   6|    -2.0|\n",
            "|  17|     0.0|\n",
            "|  13|    -2.0|\n",
            "|   9|    -2.0|\n",
            "+----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaasjeCdrOiN",
        "colab_type": "text"
      },
      "source": [
        "### Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha31JGq3rOiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totals_per_delay_hour = df2.groupBy('Hour', 'DepDelay').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6dra7murOig",
        "colab_type": "text"
      },
      "source": [
        "Now we join both and calculate what fraction of the total for each hour each level of DepDelay represents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvZRkOcsrOij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "18ab2b55-26af-42aa-909d-0d945ef075e0"
      },
      "source": [
        "totals_per_delay_hour.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------+-----+\n",
            "|Hour|DepDelay|count|\n",
            "+----+--------+-----+\n",
            "|  17|     8.0|  388|\n",
            "|  13|    19.0|  197|\n",
            "|  22|     9.0|  158|\n",
            "|  16|    76.0|   31|\n",
            "|  17|    72.0|   32|\n",
            "+----+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fwa9czvifMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c90bae01-a338-4347-b866-11a40920ed2d"
      },
      "source": [
        "all_totals = totals_per_hour.join(totals_per_delay_hour, on='Hour')\n",
        "all_totals.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+--------+-----+\n",
            "|Hour|count|DepDelay|count|\n",
            "+----+-----+--------+-----+\n",
            "|  17|36591|     8.0|  388|\n",
            "|  13|33163|    19.0|  197|\n",
            "|  22|15646|     9.0|  158|\n",
            "|  16|34761|    76.0|   31|\n",
            "|  17|36591|    72.0|   32|\n",
            "+----+-----+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxvy5dDWiz2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "outputId": "a33f5ca1-696d-4076-ed05-76dfa4718db7"
      },
      "source": [
        "all_totals['count'] / all_totals['count']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o138.apply.\n: org.apache.spark.sql.AnalysisException: Reference 'count' is ambiguous, could be: count, count.;\n\tat org.apache.spark.sql.catalyst.expressions.package$AttributeSeq.resolve(package.scala:259)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveQuoted(LogicalPlan.scala:121)\n\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:221)\n\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1274)\n\tat org.apache.spark.sql.Dataset.apply(Dataset.scala:1241)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5dce1d3b3773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_totals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mall_totals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \"\"\"\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: \"Reference 'count' is ambiguous, could be: count, count.;\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpjV7huCj3KF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "83144eb7-3c83-4f1e-c852-4c6c1bd224fa"
      },
      "source": [
        "relative_frequencies = all_totals.withColumn('rel_freq', totals_per_delay_hour['count'] / totals_per_hour['count']).cache()\n",
        "relative_frequencies.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+--------+-----+--------------------+\n",
            "|Hour|count|DepDelay|count|            rel_freq|\n",
            "+----+-----+--------+-----+--------------------+\n",
            "|  17|36591|     8.0|  388|0.010603700363477358|\n",
            "|  13|33163|    19.0|  197|0.005940355215149...|\n",
            "|  22|15646|     9.0|  158|0.010098427713153522|\n",
            "|  16|34761|    76.0|   31|8.918040332556601E-4|\n",
            "|  17|36591|    72.0|   32|8.745319887404006E-4|\n",
            "+----+-----+--------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUN-TR3trOiw",
        "colab_type": "text"
      },
      "source": [
        "### Generate distributions\n",
        "\n",
        "We have to group on the hour. Each group will be a bunch of delays and the corresponding frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ogQTAAgrOiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ed4b5236-bed4-4e18-dddf-ced14faf2b23"
      },
      "source": [
        "from pyspark.sql import functions\n",
        "\n",
        "totals_per_hour.select(functions.collect_list('count')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "| collect_list(count)|\n",
            "+--------------------+\n",
            "|[36925, 15646, 65...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUZMm9Mtm4pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "d3098e2a-29d2-40ca-b50b-4590238e4880"
      },
      "source": [
        "distributions = relative_frequencies.groupBy('Hour').agg(functions.collect_list('DepDelay').alias('DepDelays'),\n",
        "                                                         functions.collect_list('rel_freq').alias('rel_freqs'))\n",
        "distributions.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------------+--------------------+\n",
            "|Hour|           DepDelays|           rel_freqs|\n",
            "+----+--------------------+--------------------+\n",
            "|  12|[1315.0, 280.0, 3...|[2.70819228165199...|\n",
            "|  22|[9.0, 73.0, 383.0...|[0.01009842771315...|\n",
            "|   1|[270.0, 223.0, 30...|[0.00118203309692...|\n",
            "|  13|[19.0, 211.0, -18...|[0.00594035521514...|\n",
            "|  16|[76.0, 84.0, 289....|[8.91804033255660...|\n",
            "|   6|[89.0, 678.0, 540...|[1.06957591315043...|\n",
            "|   3|[157.0, 11.0, 139...|[0.005, 0.01, 0.0...|\n",
            "|  20|[173.0, 226.0, 53...|[3.17415532200042...|\n",
            "|   5|[64.0, 42.0, -19....|[4.42536619905297...|\n",
            "|  19|[131.0, 330.0, 14...|[2.90641348575857...|\n",
            "|  15|[238.0, 47.0, 584...|[2.80182679106777...|\n",
            "|  17|[8.0, 72.0, 86.0,...|[0.01060370036347...|\n",
            "|   9|[170.0, 60.0, 67....|[5.82156891282200...|\n",
            "|   4|[-8.0, 3.0, 24.0,...|[0.05385735080058...|\n",
            "|   8|[178.0, 1236.0, 1...|[5.50100393321781...|\n",
            "|  23|[108.0, 129.0, 23...|[0.00239931448157...|\n",
            "|   7|[52.0, 91.0, 51.0...|[6.22594521168213...|\n",
            "|  10|[70.0, 287.0, 332...|[5.20231213872832...|\n",
            "|  24|[-7.0, 80.0, -5.0...|[0.05, 0.025, 0.0...|\n",
            "|  21|[-21.0, 307.0, 21...|[4.72987176792095...|\n",
            "+----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKB5_WjYrOjF",
        "colab_type": "text"
      },
      "source": [
        "These groups are definitely manageable: the number of levels will be on the order of a few hundreds to a couple thousands. We can combine them into lists straight away."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fRBs3EfrOjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyReScnrrOjU",
        "colab_type": "text"
      },
      "source": [
        "Now it's be easy to use a UDF to merge the two lists and sort them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iR9oSNJrOjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsXXvslVrOjg",
        "colab_type": "text"
      },
      "source": [
        "Careful! If we keep that string return type, it might be problematic later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0CXfe_lrOjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS745GaJrOj1",
        "colab_type": "text"
      },
      "source": [
        "### Calculating the quartiles\n",
        "\n",
        "We are finally ready to calculate the quartiles! We will use a UDF.\n",
        "\n",
        "The input to our custom function will be one of the distributions coded like we did: as a list of tuples `(value, relative_frequency)`. The quartiles are defined as the values at which we cross the 0.0, .25, .5, .75 and 1.00 relative frequencies. Since the distributions are ordered, we can just iterate over one while keeping track of what portion of the total distribution we have seen, and annotate where we cross the thresholds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpSzoY9FrOj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "54d1b047-e7c2-4871-c919-94f6a6eddc1d"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(52)\n",
        "values = random.choices(range(-50, 50), k=12)\n",
        "freqs =  random.choices(range(100, 300), k=12)\n",
        "rel_freqs = [ f / sum(freqs) for f in freqs ]\n",
        "sorted(zip(values, rel_freqs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-45, 0.049394221808014914),\n",
              " (-35, 0.0717614165890028),\n",
              " (-32, 0.12628145386766076),\n",
              " (-16, 0.13000931966449208),\n",
              " (-10, 0.06244175209692451),\n",
              " (-9, 0.08527493010251631),\n",
              " (-2, 0.047530288909599254),\n",
              " (22, 0.08247903075489282),\n",
              " (41, 0.06803355079217148),\n",
              " (44, 0.05265610438024231),\n",
              " (47, 0.10531220876048462),\n",
              " (49, 0.11882572227399814)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skvikE0_qXcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc91bcdd-74bd-4609-ee71-80613ca348b6"
      },
      "source": [
        "def quartiles(values, rel_freqs):\n",
        "  result = []\n",
        "  acc = 0.0\n",
        "\n",
        "  sorted_tuples = sorted(zip(values, rel_freqs))\n",
        "  result.append(sorted_tuples[0][0])\n",
        "\n",
        "  for value, freq in sorted_tuples:\n",
        "    previous = acc\n",
        "    acc += freq\n",
        "\n",
        "    if previous < 0.25 and acc >= 0.25:\n",
        "      result.append(value)\n",
        "    if previous < 0.5 and acc >= 0.5:\n",
        "      result.append(value)\n",
        "    if previous < 0.75 and acc >= 0.75:\n",
        "      result.append(value)\n",
        "\n",
        "  result.append(value)\n",
        "\n",
        "  return result \n",
        "\n",
        "quartiles(values, rel_freqs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-45, -16, -9, 44, 49]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2D1OeyOrOj_",
        "colab_type": "text"
      },
      "source": [
        "Apply to the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFsGYxr6rOkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b22b6a9-124f-4cf8-b4ea-9dcbd84fb751"
      },
      "source": [
        "from pyspark.sql import types\n",
        "\n",
        "quartiles_udf = functions.udf(quartiles, returnType=types.ArrayType(types.DoubleType()))\n",
        "\n",
        "quartiles_df = distributions.withColumn('quartiles', quartiles_udf('DepDelays', 'rel_freqs'))\n",
        "quartiles_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Hour: int, DepDelays: array<double>, rel_freqs: array<double>, quartiles: array<double>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAUVRqS7rOkN",
        "colab_type": "text"
      },
      "source": [
        "### Plotting\n",
        "\n",
        "We got it! Let's move this over to Pandas for convenient handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFcMGd2BrOkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "93975a76-9253-4cb0-bf84-007f37366c87"
      },
      "source": [
        "pd_df = quartiles_df.toPandas()\n",
        "pd_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hour</th>\n",
              "      <th>DepDelays</th>\n",
              "      <th>rel_freqs</th>\n",
              "      <th>quartiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>[1315.0, 280.0, 375.0, 75.0, 167.0, 366.0, -20...</td>\n",
              "      <td>[2.7081922816519974e-05, 5.416384563303995e-05...</td>\n",
              "      <td>[-38.0, -5.0, -2.0, 6.0, 1371.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>[9.0, 73.0, 383.0, 165.0, 157.0, 144.0, 4.0, 6...</td>\n",
              "      <td>[0.010098427713153522, 0.00153393838680813, 6....</td>\n",
              "      <td>[-39.0, -5.0, 0.0, 22.0, 953.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[270.0, 223.0, 30.0, 98.0, 204.0, 432.0, 125.0...</td>\n",
              "      <td>[0.001182033096926714, 0.002364066193853428, 0...</td>\n",
              "      <td>[-22.0, -3.0, 13.0, 111.0, 1154.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>[19.0, 211.0, -18.0, 43.0, 200.0, 155.0, 169.0...</td>\n",
              "      <td>[0.0059403552151494135, 6.030817477309049e-05,...</td>\n",
              "      <td>[-32.0, -5.0, -2.0, 9.0, 1185.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>[76.0, 84.0, 289.0, 672.0, 176.0, 215.0, 269.0...</td>\n",
              "      <td>[0.0008918040332556601, 0.0009493397773366704,...</td>\n",
              "      <td>[-37.0, -5.0, -1.0, 10.0, 672.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Hour  ...                           quartiles\n",
              "0    12  ...    [-38.0, -5.0, -2.0, 6.0, 1371.0]\n",
              "1    22  ...     [-39.0, -5.0, 0.0, 22.0, 953.0]\n",
              "2     1  ...  [-22.0, -3.0, 13.0, 111.0, 1154.0]\n",
              "3    13  ...    [-32.0, -5.0, -2.0, 9.0, 1185.0]\n",
              "4    16  ...    [-37.0, -5.0, -1.0, 10.0, 672.0]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZCr5vsPrOke",
        "colab_type": "text"
      },
      "source": [
        "And we are ready to plot!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBWFy06zrOkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "e309c7dd-ece1-415f-de80-532e97a16ad0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for _, row in pd_df.iterrows():\n",
        "  xs.append([row['Hour']] * 5)\n",
        "  ys.append(row['quartiles'])\n",
        "\n",
        "plt.scatter(xs, ys)\n",
        "plt.gcf().set_size_inches(12, 6)\n",
        "plt.gca().set_ylim(-50, 250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-50.0, 250.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5kFMqJerOkv",
        "colab_type": "text"
      },
      "source": [
        "## Test your \"Big Data\" prototype with small data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_WZPijIrOkw",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "\n",
        "This is the whole process, collected in one place as is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdOmOfiOrOky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import types\n",
        "\n",
        "\n",
        "df = spark.read.csv('On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2018_12.csv.gz', inferSchema=True, header=True)\n",
        "\n",
        "\n",
        "df2 = df.select('*',\n",
        "                (df['DepTime'] / 100).cast(types.IntegerType()).alias('Hour'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPhqUjEDrOk8",
        "colab_type": "text"
      },
      "source": [
        "### Pyspark job\n",
        "\n",
        "In order to run the process in a cluster, we need to transform it into a pyspark job file. \n",
        "\n",
        "We need to tidy up the function definitions, add the relevant imports, and modify the input and output to use command-line arguments.\n",
        "\n",
        "We will put the result in a file called mysparkjob.py:\n",
        "\n",
        "```python\n",
        "from __future__ import print_function\n",
        "from pyspark.sql import types, functions, SparkSession\n",
        "import sys\n",
        "\n",
        "def zipsort(a, b):\n",
        "    return sorted(zip(a, b))\n",
        "\n",
        "def quartiles(histogram):\n",
        "    area = 0\n",
        "    result = []\n",
        "    \n",
        "    for value, percentage in histogram:\n",
        "        if area == 0:\n",
        "            result.append(value)\n",
        "        elif area <= .25 and area + percentage > .25:\n",
        "            result.append(value)\n",
        "        elif area <= .5 and area + percentage > .5:\n",
        "            result.append(value)\n",
        "        elif area <= .75 and area + percentage > .75:\n",
        "            result.append(value)\n",
        "        area += percentage\n",
        "    \n",
        "    result.append(value)\n",
        "    return result\n",
        "\n",
        "if __name__=='__main__':\n",
        "    \n",
        "    file = sys.argv[1]\n",
        "    out = sys.argv[2]\n",
        "    \n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    df = spark.read.csv(file, header= True, inferSchema=True)\n",
        "    df = df.select(['FlightDate', 'DayOfWeek', 'Reporting_Airline', 'Tail_Number', 'Flight_Number_Reporting_Airline', 'Origin', \n",
        "                    'OriginCityName', 'OriginStateName', 'Dest', 'DestCityName', 'DestStateName',\n",
        "                    'DepTime', 'DepDelay', 'AirTime', 'Distance'])\n",
        "\n",
        "    df2 = df.withColumn('Hour', (df['DepTime'] / 100).cast(types.IntegerType()))\n",
        "    totals = df2.groupBy('Hour').count()\n",
        "    distributions = df2.groupBy(['Hour', 'DepDelay']).count()\n",
        "    annotated = distributions.join(totals, on='Hour')\n",
        "    frequencies = annotated.withColumn('relative', distributions['count'] / totals['count'])\n",
        "    groups = frequencies.groupBy(totals['Hour'])\\\n",
        "                        .agg(functions.collect_list('DepDelay').alias('delays'),\n",
        "                             functions.collect_list('relative').alias('relatives'))\n",
        "\n",
        "\n",
        "\n",
        "    zipsort_typed = functions.udf(zipsort, types.ArrayType(types.ArrayType(types.FloatType())))\n",
        "    distributions = groups.withColumn('distributions', zipsort_typed('delays', 'relatives'))\n",
        "\n",
        "\n",
        "\n",
        "    quartiles_udf = functions.udf(quartiles, returnType=types.ArrayType(types.FloatType()))\n",
        "\n",
        "    result = distributions.select('Hour',\n",
        "                                  quartiles_udf('distributions').alias('quartiles'))\n",
        "\n",
        "    result.write.json(out)\n",
        "    spark.stop()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_AmtckdrOk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZMw3jIrOlN",
        "colab_type": "text"
      },
      "source": [
        "### Running with spark-submit\n",
        "\n",
        "If the following works, we are ready to test it in the cluster!\n",
        "\n",
        "```python\n",
        "spark-submit mysparkjob.py On_Time_On_Time_Performance_2015_8.csv out.csv\n",
        "```"
      ]
    }
  ]
}